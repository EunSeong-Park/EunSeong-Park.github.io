---
title:  "[OS 4] CPU 스케줄링"
tags: OS
toc: true
---

# Intro
이번엔 CPU 스케줄링이다. CPU는 컴퓨터의 중요한 자원이기 때문에, 그것의 효율적인 관리가 필요하다. 그래서, OS를 이해하고 설계하기 위해, CPU 스케줄링의 개념은 필수적이다.

# Scheduling
스케줄링(scheduling)이란, 다수의 스레드가 처리될 준비가 되었을 때, 직후에 처리할 대상을 결정하는 것을 의미한다. 꼭 스레드가 아니더라도, 패킷, 웹 요청 등도 스케줄링의 대상이 될 수 있다. 여기선 CPU 스케줄링을 위주로 이야기를 해볼 것이다.

CPU 스케줄링은 프로세서의 수에 따라 그 policy가 다르다. 단일 프로세서(uniprocessor)의 경우, FIFO, round robin 등을 사용할 수 있을 것이고, 다중 프로세서(multiprocessor)의 경우, affinity scheduling, gang scheduling 등을 사용할 수 있을 것이다. 이들은 나중에 천천히 알아보자.

## Terms

- Task/job : 처리해야 하는 작업들. 마우스 클릭 같은 사소한 user request부터, 웹 요청, 쉘 커맨드 등 다양하다.
- Overhead : 스케줄러에 의해 수행되는 '추가적인 작업(work)'
- Fairness : 서로 다른 사용자에 대해 얼마나 동등하게 performance가 가해지는지의 정도
- Predictability : 시간에 따른 perfomance가 일관적인 정도
- Workload : 시스템이 수행해야 하는 task의 집합
- Preemptive scheduler : 실행되고 있는 task로부터 자원을 가져올 수 있는 스케줄러. (c.f. non-preemptive)
- Work-conserving : 자원을 항상 busy하게 하는 방식 (c.f. non-work-conserving)

수업 때 잠깐 언급된 내용인데, 보통은 work-conserving이 효율적이지만, 어떤 때엔 non-work-conserving이 유용할 수도 있다고 한다. 위키에 따르면,

> Non-work conserving schedulers are sometimes useful to enhance predictability and reduce termination jitter for the activities carried out by a computing and communication system. (...) Sometimes, a non-work conserving scheduler may be useful to enhance stability of a system.

다음은 performance를 논의하기 위한 용어들이다.

- Throughput : 단위 시간 당 처리된 tasks (# of jobs/time)
- Turnaround time : 어떤 task가 처리되는 데 걸린 시간 ( T_finish - T_arrival)
- Response time : 요청이 제출 되고, 첫 응답이 만들어지는 데 걸린 시간 (T_response - T_arrival)
- Waiting time : task 측면에선, ready/wait state로 소비한 총 시간. 시스템 측면에선 시스템 내 총 waiting time의 평균.


# Uniprocessor Policies
## FIFO (First-In-First-Out) Scheduling
큐(queue)가 떠오르는 선입 선출 방식이다. 단어 그대로, 먼저 들어온 작업이 먼저 처리된다는 의미인데, FCFS(First-Come-First-Served)라고도 한다. 그 의미와 구현 방식이 꽤 직관적이고 간단한데, 이러한 방식에 큰 문제점이 하나 있다.

![](/imgs/os/os13.png)

위와 같이, 시간이 오래 걸리는 작업이 맨 앞에 온다면, 뒤에 있는 짧은 작업은 하염없이 기다려야 해서, 전반적인 turnaround time이 길어지게 된다. 위 그림에서는 평균 (24+27+30)/3 = 27의 turnaround time을 가지며, 평균 (0+24+27)/3 = 17의 waiting time을 가진다. 이러한 상황을 convoy effect라 한다.

## SJF (Shortest-Job-First) Scheduling
위의 상황에서, turnaround/waiting time을 줄이려면, 짧은 작업을 먼저 처리해야 할 것이다. SJF는 그런 아이디어에 따라, 남은 work의 양이 가장 적은, shortest한 작업을 우선적으로 처리한다. SRTF(Shortest-Remaining-Time-First)라고도 불린다.

위의 예시에 SJF를 적용하면, 평균 turnaround time은 (3+6+30) = 13이, 평균 waiting time(AWT)은 (0+3+6)/3 = 3이 될 것이다. 절반 이상이 줄었다. 

SJF를 스케줄러의 선점 여부에 따라 구분해 생각해볼 수 있다. 비선점적(non-preemptive)이라면 한 번 작업이 들어오면, 그것이 끝날 때까지 선점할 수 없겠지만, 선점적이라면, 어느 시점에서 처리하는 작업보다 짧은 작업이 생기면 이를 선점할 것이다. 그래서 그 타입에 따라 스케줄링의 양상이 달라질 것이다.

![](/imgs/os/os14.png)

이렇게 보면 SJF는 꽤 최적의 알고리즘처럼 보이지만, 몇 가지 문제점이 있다.

- AWT(Average Waiting Time)는 최소화되지만, turnaround time은 그렇지 않다.
- 처리가 오래 걸리는 프로세스는 자원의 할당을 위해 무기한 대기해야 할 수도 있다. (indefinite blocking 또는 starvation이라고 한다.)
- 각각의 task가 가지는 CPU burst time을 알지 못할 수도 있다.

## Priority Scheduling
SJF는 우선순위(priority) 스케줄링의 특수한 케이스로 볼 수 있다. Task의 CPU burst가 짧으면 높은 우선순위를 가진다고 볼 수 있기 때문이다. 물론, 이 경우에도 SJF와 마찬가지로, 선점적일 수도, 비선점적일 수도 있고, 상황에 따라 starvation을 야기할 수 있다. 

Starvation을 방지하기 위한 해결책으론 aging이 있다. 오랫동안 대기 중인 프로세스의 우선순위를 조금씩 증가시킴으로써, 언젠간 모든 작업이 스케줄될 수 있다.

## Round-Robin Scheduling
라운드 로빈(RR, Round-Robing) 스케줄링 방식은 선점적이다. 적절한 고정된 주기(time quantum, or time slice)를 정해, 그 주기에 따라 작업들을 처리한다. 할당량을 채우기 전 작업이 끝난다면 그대로 작업을 제거하고, 할당량을 전부 채웠다면 인터럽트를 걸어 컨텍스트 전환을 통해 다음 작업으로 옮긴다. RR 스케줄링은 그렇게 원형 큐를 도는 것처럼 작업이 이루어진다.

![](/imgs/os/os15.png)

위 그림은 단위 시간 4를 할당량으로 지정하여, burst time이 24, 3, 3인 P1, P2, P3을 처리하는 모습이다. 

라운드 로빈 방식은 여러 면에서 유용한데, 우선 response time이 짧아지고, 할당량이 정해져 있으므로 일정 시간 이상 기다리지 않음을 보장해줄 수 있다. 이런 점에서 fair한 스케줄링 방식이라 볼 수 있다.

라운드 로빈 방식에서 중요한 것은 시간 할당량의 설정이다. 너무 길면 FIFO와 다를 게 없고, 너무 짧으면 컨텍스트 전환 등에 의한 오버헤드로 인해 속도가 느려질 것이다. 즉, 우리는 라운드 로빈으로 인한 오버헤드와 response 및 turnaround time의 단축 사이에서 적절한 최적점을 찾아야 한다. 예를 들어, 동일한 길이의 작업 여러 개를, 아주 작은 할당량으로 라운드 로빈을 사용한다면, 빠른 응답 시간을 가지지만, 작업들이 끝에 한꺼번에 완료되어 굉장히 나쁜 처리 시간을 가질 것이다.

작업이 무엇에 의해 bound되는지도 중요하다. CPU-bound라면 컨텍스트 전환 등에 의한 오버헤드를 줄이면서도, 적절한 처리량을 보장해야 하므로, (적당한 수준에서) 상대적으로 긴 할당량이 적절할 것이다. I/O-bound라면 CPU나 기타 장치의 utilization을 보장하기 위해 상대적으로 짧은 할당량이 적절할 것이다. 

## Fairness Issue: Max-Min Fairness
라운드 로빈 방식이 공정하다(fair)고 언급했었는데, 여기서 문제가 있다. 무엇이 공정한 건지, 그 공정함이 실제로 효과가 있는지에 관한 문제다. 예를 들어보자. 실제로 대부분의 프로그램은 I/O-bound와 CPU-bound를 모두 포함한다. 여기서 I/O-bound한 작업과 CPU-bound한 작업에게 동일한 할당량을 제공하는 게 유의미한 공정함일까? 양 쪽 측면 모두에게 낭비가 될 것이다. 이런 점에서 보면, 단순히 동일한 시간을 분배하는 게 공정함의 본질은 아닐 것이다.

그럼 각종 task가 혼재하는 상황에서도 공정함이 유의미해지도록, 할당량을 새로운 방법으로 분배해보자. 다음과 같은 방법을 따르면 된다.

1. 먼저, 각 task에 대해 일반적으로 균일하게 분배한다.
2. 필요한 할당량을 채우거나 초과한 작업은 우선적으로 스케줄하고, 남은 할당량을 다시 분배한다.

예시로, 각각의 할당량이 1.9, 2.5, 4, 5인 네 개의 작업에 대해, 10의 capacity를 분배하는 상황을 생각해보자.

    {2.5, 2.5, 2.5, 2.5} // 균등 분배
    {1.9, 2.5, 2.5, 2.5} // 초과분 제거 (1st)
    {1.9, 2.7, 2.7, 2.7} // 초과분 재분배
    {1.9, 2.5, 2.8, 2.8} // 초과분 제거 (2nd) 및 재분배

## MFQ(Multilevel Feedback Queue) Scheduling
MFQ는 다수의 라운드 로빈 큐로 구성되어 있다. 큐들은 각자의 우선순위를 가지고 있으며, 높은 우선순위의 큐는 짧은 시간 할당량을 가진다. 스케줄러는 가장 높은 우선순위의 큐에서 시간이 만료되면 다음 순위의 큐로 이동한다.

![](/imgs/os/os16.png)

이럼으로써 라운드 로빈에서의 장점과 함께, 프로세스의 범주나 특성에 따라 (그러면서도 프로세스 각각의 정보를 직접적으로 필요로 하지 않는다) 융통성 있게 스케줄링이 가능하다. 또, I/O-bound task 같은, 빨리 처리될 수 있는 작업을 위쪽 큐에 할당하면 전반적인 처리 및 응답 시간이 빨라진다.

이러한 MFQ는 다음과 같은 매개변수에 의해 정해지는데, 이들은 적절한 알고리즘을 사용해 설계 중인 특정 시스템에 부합하도록 만들 수 있다.

- 큐의 개수
- 각각의 큐를 위한 스케줄링 알고리즘
- 어떤 프로세스가 높은 큐로 승급 / 낮은 큐로 강등시키는 시기를 결정하는 알고리즘
- 프로세스가 서비스를 필요로 할 때 프로세스가 들어갈 큐를 결정하는 방법

## CFS(Completely Fair Scheduler)
CFS는 Linux의 스케줄러로, 실행 가능한(runnable) 작업은 각자의 가상 런타임(virtual runtime, vruntime)을 가진다. 이는 실행한 시간에 비례하여 monotonic하게 증가한다. 

이 때, 타임 인터럽트가 발생하면, 가장 낮은 vruntime을 가진 작업을 골라, 이것의 time slice(할당량)를 동적으로(dynamically) 계산하여 돌린다. 그리고 다른 작업이 더 작은 vruntime을 가지게 되면 언스케줄링한다.

CFS는 RB-Tree에 의해 구현 및 관리될 수 있는데, 이는 balanced tree이며, 모든 기본적인 operation인 log n에 bound되기 때문이다. 여기서 우선순위는 vruntime과 가중치에 의해 결정되는데, I/O-bound한 작업이라면, 적은 CPU burst로 인해 낮은 vruntime을 가지므로 스케줄링에서 높은 우선순위를 가진다.


# Multiprocessor Policies
멀티프로세서 시스템이라면 load sharing 등을 활용해 효과적으로 작업을 처리할 수 있지만, 그만큼 스케줄링도 복잡해진다. 기본적으로 다수의 프로세서를 어디에 할당시킬지를 정해야 하기 때문이다. CPU를 돌려가며 하나의 task를 사용하는 경우는 어떨까? 전환 과정에서 여러 요인에 의한 코스트가 발생할 것이다. 다수의 프로세서가 하나의 MFQ를 공유하는 건 어떨까? 액세스를 위해 동기화가 필요하고, 캐시 성능의 저하 등 이 또한 여러 문제가 있을 것이다.

## Processor Affinity
이에 대한 해결책 중 하나로, 각각의 코어에 ready list를 할당하는 방법이 있다. 하지만 단순히 생각해보면 이는 work-conserving할 수가 없는데, idle한 프로세서는 다른 프로세서로부터 프로세스를 빼앗아야 하기 때문이다. 이는 또 캐시 성능 저하 등의 부작용을 낳는다.

우리는 이러한 문제를 프로세서 친화성(affinity)을 가지게 함으로써 해결할 수 있다. 스레드를 그것이 최근에 실행된 프로세서의 ready list에 넣음으로써, 프로세스의 이주(migration)를 최소화해 캐시를 무효화하고 다시 채우는 코스트를 줄일 수 있다.

또, 시스템의 메모리 구조가 친화성에 영향을 줄 수 있다. NUMA(Non-Uniform Memory Access, 비균등 메모리 접근) 구조에서는, CPU가 같은 보드 내의 메모리에 접근할 때 보다 빠르다. 이러한 구조에서 특정 CPU와 친화성을 가지는 프로세스는 그 보드의 메모리에 할당될 수 있다.

![](/imgs/os/os17.png)

## BSP(Bulk Synchronous Parallelism)
멀티프로세서를 활용하기 위한 동기적 병렬 컴퓨팅 모델이다. 각각의 프로세서는 병렬적으로 로컬 데이터를 계산하고(concurrent compuation), 배리어(barrier)에서 모든 프로세서의 작업이 끝나길 기다린 뒤(barrier synchronization), 이후 각자의 데이터를 교환하는(communication) 방식이다.

물론 그 구조상, 배리어에서의 동기화를 위해 어느 정도의 지연(tail latency)이 발생할 수 있다. 이를 최소화하기 위해선, 각 프로세서에게 가능한 한 균등하게 workload를 배분해주는, 부하 균등화(load balancing)이 필요하다.

![](/imgs/os/os18.png)

위와 같은 방식으로 BSP가 동작한다.

## Gang Scheduling
갱 스케줄링(gang scheduling)은 어떤 프로세스나 스레드에 대해, 다수의 프로세서가 동기적으로 이를 처리하는 스케줄링 방식이다. 이는 프로세서 간 통신과 데이터 공유를 수반한다.

이는 스케줄링 과정에서의 오버헤드를 줄이고, 단편화(fragmentation)를 줄여준다.
