---
title:  "[OS 5] Synchronization 1"
tags: OS
toc: true
---

# Intro
프로세스 간 데이터를 공유하기 위해, 어떤 데이터 공유를 위한 공간을 할당한다고 생각해보자. 이 때, 다수의 프로세스가 동시에 읽기/쓰기를 진행하면 문제가 발생할 수 있다. 데이터를 일관성있게 관리하고, 각 프로세스가 특정 데이터에 대해 질서있게 동작하려면 어떻게 해야 할까?

이런 문제의 일상적인 예시로, 은행 계좌를 생각해볼 수 있다.

> A와 B가 어떤 한 계좌를 공유해 사용하고 있다. 1000원이 있는 계좌에서 A와 B가 각각 700원을 꺼내려 한다. 정상적인 상황이라면 A와 B 중 한 명만 700원을 꺼내는 데 성공하고, 나머지는 잔액 부족으로 실패할 것이다. 하지만 은행 시스템이 적절하게 설계되지 않아, A와 B가 잔액을 참조할 시점에 모두 1000원이어서, 두 명 모두에게 700원을 출금해준다면 어떻게 될까?

이러한 상황을 막기 위해, 우리는 은행 계좌의 잔액을 **동기화(synchronize)** 해야 한다.


# Synchronization
## Terminologies
우선 몇 가지 용어를 이해하고 넘어가자.

- **Race condition** : 다수의 스레드가 같은 데이터를 동시적으로 조작하려 하고, execution의 결과가 그러한 데이터 액세스의 순서에 의존하는 상황.
- **Critical section** : 공유 자원에 액세스하는 코드의 일부. 즉, race condition을 유발하는 부분.
- **Mutual exclusion** : 오직 하나의 스레드만이 critical section을 실행하도록 하는 것. (해당 부분 실행 중 다른 스레드의 실행을 막는 등으로)
- **Lock** : 누군가가 어떤 행동을 하는 걸 막는 방법 또는 행동.

이 용어들을 보면 우리가 문제를 해결하기 위해 어떤 것을 해야 할지 대충은 감이 오는 것 같다. 

## Cooperating / Independent Process
사실, 모든 프로세스가 독립적이라면 동기화 문제를 다룰 필요가 없겠으나, 이는 현실적으로 불가능하다. 프로세스 간의 상호작용과 협력으로 얻는 이점이 너무나도 많기 때문이다.

프로세스 간 상호작용으로 우리는 서로 정보를 교환하고, 좋은 성능을 얻고, 향상된 모듈러리티와 편의성을 누렸다. (프로세스 파트에서 언급했다.)

하지만 이는 race condition을 유발할 수 있기 때문에, 이를 적절한 동기화 기법으로 잘 해결해주어야 한다.

## Synchronization Problem
동시성(concurrency)은 굉장히 중요하지만, 이는 비결정적(non-deterministic)인 결과를 낳을 수 있다. 즉, 결과에 시간 의존성이 발생하거나 입력 외의 어떤 상황에 구애받게 된다는 의미다. 이러한 상황은 상당히 바람직하지 않은데, 의도치 않은 결과가 튀어나올 수 있고, 디버그를 어렵게 만들기 때문이다. 그래서, 우리는 동기화를 통해 특정 상황에서 동시성을 제한할 수 있어야 한다.

## Producer-Consumer Problem
어떤 버퍼나 큐에 대해 생산자와 소비자가 구분되어있다고 가정하자. 분명한 사실은, 우리는 다음과 같은 상황을 피해야한다는 점이다.

- 빈 버퍼를 pop한다.
- 꽉 찬 버퍼에 push한다.

그리고 아래 코드를 보자.

```c
// Producer
while (true){
    while (count == BUFFER_SIZE); // do nothing
    buffer[in] = SomeProduction;
    in = (in + 1) % BUFFER_SIZE; // round queue
    count++;
}

// Consumer
while (true){
    while (count == 0); // do nothing
    SomeConsumption = buffer[out];
    out = (out + 1) % BUFFER_SIZE
    count--;
}
```
위 코드는 뭐가 문제인가? 일단, `count`는 두 주체가 함께 공유하는 정수인 것으로 보인다. `count`로의 동시적 접근은 race condition을 만들 수 있다. 왜냐?

예를 들어 `count = 3`이라 하자. 소비자와 생산자가 동시에 카운트를 늘리고 줄이는 걸 시도한다면 최종적으로 `3`이 되어야하지만, 실제론 다른 결과가 나올 수 있다. `x++`는 `Reg = Mem(count); Reg += 1; Mem = Reg`의 절차를 따름을 기억하자. 이 과정이 인터리빙된다면, 결과는 `2`가 나올 수도, `4`가 나올 수도 있다.

이런 점에서 보면, `count++, --`는 critical section에 해당하고, 그것에 의해 race condition이 만들어졌다고 볼 수 있다. 아무튼 좋진 않은 상황이다.

## Solutions
이러한 critical section problem을 해결하기 위해선 다수의 스레드가 해당 영역에 동시에 접근하는 걸 막아야 할 것으로 보인다. 해당 영역으로의 동시 접근은 race condition을 유발하기 때문이다. Critical section에 대한 문제를 해결하기 위해, 어떤 프로세스/스레드가 자신의 critical section에서 실행된다면 다른 프로세스/스레드는 그들 자신의 critical section에서 실행될 수 없도록 해야 한다. 이를 **Mutual exclusion**이라 한다.

또, 그러면서도, critical section에 들어가고자 하는 프로세스는 (별 다른 문제가 없다면) 언젠간 들어가야 할 것이다. 이를 **Progress**라 한다.

마지막으로, 모든 프로세스가 non-zero speed로 진행된다고 가정하자. 그렇다면, critical section에 대한 진입을 요청한 프로세스는, 유한 시간만을 대기해야 한다. 즉, **Bounded Waiting**이 요구된다.

우리의 솔루션은 위 세 항목을 모두 만족시켜야 할 것이다.

### Peterson's Solution
**Peterson's solution**은 critical section problem을 해결하기 위한 algorithmic method를 제안한다. 어떤 두 프로세스 $P_i$, $P_j$가 있고, critical section에 진입할 (공유된) 번호를 `turn`이라 하고, critical section에 진입할 준비가 되었는지의 여부를 나타내는 (공유된) bool 배열 `flag[2]`가 있다 하자. Pi는 다음과 같은 구조를 가진다.
```c
flag[i] = true;
turn = j;

while (flag[j] && turn == j); // do nothing
    (critical section)
flag[i] = false;
    (remainder section)
```
$P_i$가 자신의 critical section에서 실행되려면 `turn`이 $i$여야 하고, $P_j$의 경우엔 `turn`이 $j$여야 한다. 어떤 경우에도 `turn`이 두 값을 가질 수는 없으므로, 두 프로세스 중 하나는 critical section에서 실행될 수 없다. 그러한 점에서, 상호 배제는 잘 지켜지며, deadlock도, starvation도 일어나지 않는다.

다만 여전히 busy-waiting으로 자원을 낭비한다는 점과, 인터럽트와 같은 하드웨어적 이벤트나 명령어의 reordering 등에 의해 교착이 발생할 수 있다는 점에서 한계가 있다.

### Locks
우리는 **락(lock)**을 통해 critical section problem을 해결할 수 있다. Critical section에 진입하려는 대상은 반드시 `acquire`를 통해 lock을 획득(acquire)해야 한다. 이후 critical section을 빠져 나오면 `release`를 통해 `lock`을 반납해야 한다. `acquire`는 lock이 획득되기 전까지 절대로 리턴하지 않기 때문에, 그 자체로 상호 배제를 구현할 수 있다.

Lock의 구현 및 사용은 다음과 같은 사항을 요구한다.

- **Correctness** : 상호 배제, deadlock의 미발생, starvation의 미발생이 잘 이루어져야 한다. 잘못 설계된 lock이라면, 다수의 스레드가 critical section에 진입하려는 상황에서, 아무도 lock을 획득하지 못해 아무 것도 진행되지 않는 교착 상태(deadlock), 또는 어떤 스레드가 영원히 lock을 획득하지 못하고 대기하게 되는 starvation이 발생할 수도 있다.
- **Fairness** : 모든 스레드는 lock을 획득하기 위한 동일한 기회가 주어진다.
- **Performance** : 이러한 과정은 CPU 오버헤드를 최소화하는 방식으로 구현되어야 한다.

**Spinlock**은 lock을 얻기 위해 lock을 얻을 때까지 무한정 루프를 돌리면서 대기하는 방식으로 구현된 lock을 의미한다. 얻을 때까지 빙빙 돌아서(spin) spinlock이라고 한다. 따라서 다음과 같은 간단한 방식으로 구현될 수 있을 것이다.
```c
acquire(lock):
    while (lock != 0);
    lock = 1;

release(lock):
    lock = 0;
```
하지만 spinlock은 생각만큼 이상적으로 작동하지 않는데, `acquire`는 atomic하지 않기 때문이다. 예를 들어 두 `acquire`가 인터리빙되었다고 치자, 그러면 두 호출자 모두 lock을 획득해 제대로 상호 배제가 이루어지지 않을 것이다. 물론 `release`는 atomic하다.

아니 근데 여기서 atomic하다는 게 뭘까? Atomic하다는 건...

- **Uninterruptible**: atomic한 함수는 인터럽트 등에 의해 방해받지 않는다.
- **All or None**: 함수는 반드시 완전히 실행되거나, 아예 실행되지 않아야 한다.
  
근데 이걸 어떻게 atomic하게 만들어야 하나..?

### HW Supported Synchronization
우리는 하드웨어가 지원하는 일부 특별한 atomic instruction을 사용해 동기화 문제를 쉽게 해결할 수 있다.

`TestAndSet()`과 `CompareAndSwap()`이라는 특별한 명령어를 생각해보자. 물론 실제론 없는 추상적인 명령어고, 보통 머신마다 같은 역할을 수행하는 명령어가 따로 있다.

`TestAndSet`은 old boolean을 리턴하면서 그와 동시에 그것을 true로 업데이트하는 atomic한 함수다.
```c
    bool TestAndSet(bool * target){
        bool rv = * target;
        *target = true;
        return rv
    }
```
`CompareAndSwap`은 old value가 예상된 값과 같을 경우에 스왑하는 atomic한 함수다.

```c
int CompareAndSwap(int * value, int expected, int new_value){
    int tmp = *value;
    if (*value == expected)
        *value = new_value;
    
    return temp;
}
```
이 둘을 활용해 동기화를 구현해보자.

```c
// TestAndSet
do {
    while (TestAndSet(&lock)); // do nothing
        (critical section)
    lock = false; // release lock
        (remainder section)
} while (true);

// CompareAndSwap
do {
    while (compare_and_swap(&lock, 0, 1) != 0); // do nothing
        (critical section)
    lock = 0;
        (remainder section)
} while (true);

```

다만 이러한 명령어는 멀티 프로세서에서는 구현이 어렵고, 애플리케이션 개발에서 사용하기엔 어려움이 있다. 그래서 다음엔 확실하면서도 강력한 도구인 세마포어(semaphore)를 사용해볼 것이다. 물론 다음에 ㅎ

