---
title:  "4 정렬 (1)"
tags: Algorithms
toc: true
key: algo4
---

# Intro
정렬은 내가 가장 싫어하는 파트다. 아무튼, 이번엔 정렬 전, 무작위 배열을 만드는 방법을 간단하게 알아본다. 그 후 힙 정렬에 대해 자세히 알아보고, 우선순위 큐에 대한 개념을 알아보고 가자.


# Permutation
정렬을 하기 전에, 무작위 배열을 생성해 input으로 사용하고 싶다. 모든 경우의 배열이 동일 확률로 나타나는 알고리즘을 짜보자.

## Permute by Sorting

![](/imgs/algorithm/algo5.png)

각 원소에 특정 범위 내에서 무작위 값을 뽑아내어, 이를 바탕으로 A를 재배치하는 방식이다. 예를 들어, [1, 2, 3, 4, 5]가 있다면, [28, 13, 54, 123, 94]과 같은 배열이 가능할 것이다. 이를 오름차순이나 내림차순으로 보아, [4, 5, 3, 1, 2], 혹은 [2, 1, 3, 5, 4]로 재배치할 수 있다.

모든 entry가 유일할 확률은 1-1/n이고, 유일하지 않다면 적당히 처리하면 될 것이다(이건 잘 모르겠는데 누가 좀 알려줬으면 좋겠다). 하지만 정렬로 인해 꽤 코스트가 큰 편이다.

## Randomize in Place

![](/imgs/algorithm/algo6.png)

i-th entry를 무작위 위치로 스왑하는 방식이다. Iteration 마다 O(1)이므로, O(n)에 끝낼 수 있다. 이 알고리즘이 진짜로 uniform random permutation일까? 달리 말하면, 모든 배열의 확률은 1/n!일까?

이전에 배웠던 방법으로 검증해보자. 바로 loop invariant를 이용하는 것이다.

![](/imgs/algorithm/algo7.png)

__Initialization__ : 초기 empty array는 확률이 1(n!/n!)인 0-permutation이다.

__Maintenance__ : i-th iteration 전, (i-1)-permutation은 각각 (n-(i-1))!의 확률을 가진다고 가정하자. 이제 그 부분배열이 [x1, x2, ..., xi-1]로 구성되어 있고(E1), 그 뒤에 xi가 올(E2) 확률이 (n-i)!/n!임을 보이면 된다. 즉, P(E1 and E2) = P(E2|E1)P(E1)이다.

- P(E2|E1)은 xi부터 xn 사이에서 xi를 뽑는 확률이다. 즉, 1/(n-(i-1)) 이다.
- P(E1)은 가정에 의해 (n-(i-1))!/n! 이다.
- 즉, 정리하면 (n-i)!/n! 이다.

__Termination__ : iteration이 끝나면, i = n+1이고, 그 부분배열은 확률이 (n-(n+1)+1)!/n! = 0!/n! = 1/n!인 n-permutation이 된다.


# Sorting Algorithms
정렬은 그 종류에 상관 없이, 어떤 n-length 숫자 배열을 받아, 같은 원소를 가지며 정렬된 배열을 리턴하면 된다. 정렬의 방식을 분류하기 위한 여러 방법이 있다.

- In-place : 추가 공간을 필요로 하지 않고, 주어진 자료 구조(array) 내에서 정렬하는 경우
- Stable : 정렬 시, 같은 값의 위치가 뒤바뀌지 않는 경우
- Comparison : 값을 비교함으로써 정렬하는 경우, 이 경우 nlogn에 lower-bound가 존재한다.

# Heap Sort
힙 정렬(heap sort)은 힙(heap) 자료 구조를 이용한 정렬 방식이다. 힙을 이용한다곤 하지만, 실제로 배열을 힙에 옮겨담는 과정은 필요 없다. 배열의 인덱스를 힙 구조에 대응시키면 그만이기 때문이다.

Time Complexity | In-Place | Stable | Comparison
---|---|---|---
O(nlogn) | O | X | O

그 전에 힙 자료 구조가 무엇인지 잘 떠올려보자. 난 까먹어서 다시 구글 봤다. 아무튼, 힙은, nearly complete한 이진 트리다. 또 max-heap과 min-heap이란 개념이 있는데, 전자의 경우, 부모 노드가 자식보다 무조건 크거나 같은 힙을, 후자의 경우, 부모 노드가 자식보다 무조건 작거나 같은 힙을 의미한다. 우리는 max-heap을 사용할 것이다. 힙과 관련된 operation으론 다음과 같은 것들이 있다.

- Max-Heapify : max-heap의 성질을 유지하기 위해 조작한다. O(logn)
- Build-max-heap : 주어진 배열을 max-heap으로 만든다. O(n)
- Heapsort : 배열에 대한 힙 정렬을 수행한다. O(nlogn)

## MAX-HEAPIFY
Max-heapify는 다음과 같은 재귀적 절차로 이루어진다.

1. 주어진 힙 A와 어떤 노드 인덱스(i)에 대해, 왼쪽 자식(L)과 오른쪽 자식(R)이 있다.
2. i와 L을, 그리고 i와 R을 비교해, 셋 중 최댓값을 가지는 인덱스를 찾는다.
3. i 자신이 최대가 아니면 최댓값을 가진 자식과 스왑한다.
4. 변경된 위치를 인덱스로, 다시 재귀 호출한다.

![](/imgs/algorithm/algo8.png)

이는 특정 노드의 제 위치를 찾아준다. 그리고 nearly complete한 힙의 특성으로, 자식 서브트리는 최악의 경우에도 2n/3의 크기를 넘지 않는다. 즉, T(n) <= T(2n/3) + O(1)인데, 이를 풀면 T(n) = O(logn)이고, 이는 힙의 높이(h)에 해당한다. 즉, O(h)다.

## BUILD-MAX-HEAP
모든 단일 리프 노드는 max-heap이다. 이들의 부모에게 max-heapify를 가하면 부모 서브트리도 max-heap이다. 이를 루트까지 올라가면서, bottom-up 방식으로 max-heap을 만들 수 있다.

![](/imgs/algorithm/algo9.png)

반토막 쳐서 for를 돌리는 건, 리프는 이미 max-heap이라 추가적인 작업이 필요 없기 때문이다. Correctness를 검증하고 싶으면, "임의의 i-th node에 대한 build를 수행하기 전, i+1 ... n 노드는 max-heap의 root다"를 loop invariant로 설정하여 확인하면 된다.

__Initialization__ : floor(n/2) + 1부터 n은 리프 노드이므로 이미 max-heap의 루트다.
__Maintenance__ : max-heapify는 i를 max-heap의 루트로 만든다. 즉, i, i+1, ..., n 노드가 전부 max-heap의 루트이므로, i+1를 build할 때, loop invariant를 만족시킨다.
__Termination__ : i=0이면, 노드 1은 최종적으로 전체 max-heap의 root가 된다.

그렇다면 코스트는 어떨까? 높이가 h면, 노드 수는 N(h) = ceil(n/2^(h+1))에 bound된다. 각 노드는 자신이 root인 sub-max-heap의 높이에 맞추어 코스트가 들어가므로, sum{h=0 to [lgn]}N(h)O(h)이고, 이를 정리하면 O(n)이다.

## HEAP-SORT
최종적으로, 주어진 배열 A에 대해 힙 정렬을 수행하자.

![](/imgs/algorithm/algo10.png)

배열에 의해 생성된 max-heap에서 가장 큰 원소를 하나씩 제거한 뒤, 배열에 넣고, 다시 max-heap property를 맞추기 위해 재배치한다. 초기 힙 빌드는 O(n)이지만 한 번만 수행하니 됐고, 가장 큰 원소를 찾는 건 코스트가 O(1)이고(root에서 바로 찾을 수 있으니), n개의 원소에 대해 max-heapify를 수행하니 O(nlogn)이다.

## (+) Priority Queue
아 데이터 구조의 악몽이 다시 떠오른다. 우선순위 큐(priority queue)는 어떤 원소 집합 S에 대해, 각각이 고유의(유일하단 의미는 아니다) 키(key)를 가져, 그 키를 기준으로 순서가 배정되는 큐를 의미한다. 우선순위 큐에 대해선 다음과 같은 operation이 가능하다.

- `Insert(S, x)`: S에 원소 x를 삽입한다.
- `Max(S)`: 가장 큰 key를 가지는 원소 x를 리턴한다.
- `Extract-max(S)`: 가장 큰 key를 가지는 원소 x를 리턴하고, 큐에서 해당 원소를 제거한다.
- `Increase-key(S, x, k)`: x의 key를 원래의 key보다 큰 k로 변경한다.

최소, 최댓값을 리턴/추출할 수 있는 min/max-priority queue는 min/max-heap 구조에 의해 구현될 수 있다. 최대 또는 최솟값이 힙의 루트에 존재하기 때문에, 리턴은 O(1)로, 추출은 heapify를 포함하여 O(logn)의 코스트로 수행할 수 있다. 우와!

힙과 관련있어 그런진 모르겠지만, 힙 정렬 뒤에 내용이 나오길래 정리해봤다.

# Quick Sort
주어진 배열에 대해 적당한 피벗(pivot)을 잡고, 피벗을 기준으로 좌/우로 나누며 재귀적으로 수행하는 정렬 알고리즘이다. 

Time Complexity | In-Place | Stable | Comparison
---|---|---|---
O(nlogn), worst-case:O(n^2) | O | X | O

퀵 정렬 또한 분할 정복 알고리즘의 일종이다. 분할 정복의 관점에서 퀵 정렬의 절차를 알아보자.

- Divide: 주어진 배열 A[p ... r]과 그 내부의 피벗 A[q]에 대하여, A를 A[p...q-1], A[q...r], 두 부분 배열로 분할한다. 이 때, 분할된 배열은 비어있을 수도 있다. 이후 좌측에는 피벗보다 작은 원소를, 우측엔 피벗보다 큰 원소를 넣는다.
- Conquer: 피벗에 의해 분리된 부분배열에 대해 재귀적으로 퀵 정렬을 가한다.

![](/imgs/algorithm/algo11.png)

이 알고리즘의 correctness를 판단하기 위해, loop invariant를 다음과 같이 정하자. "모든 배열의 인덱스, k에 대해..."

- k가 p와 i(분할 경계) 사이에 있다면, A[k] <= x다.
- k가 p+1과 j-1(피벗 바로 앞) 사이에 있다면 A[k] >= x다.
- k가 j(피벗)에 있다면 A[k] = x다.

- Initialization : i= p-1, j=p인 경우로, 자명하게(trivially) 참이다.
- Maintenance : A[j] > x면 스왑이 발생하지 않고, A[j] <= x면 스왑이 발생한다. 그로써 loop invariant를 만족하게 된다.  
- Termination : j=r에 도달해 정렬이 종료될 때, 이 경우 또한 loop invariant를 만족한다. 즉, p<=k<=i인 모든 k는 A[k] <=x고, i+2<=k<=r인 모든 k는 A[k] > x다.

## Performance
### Worst-Case
퀵 정렬은 각 분할에 대해서 피벗을 기준으로 고르게(evenly) 나누어질 때 가장 효율적이다. 달리 말하면, uneven하게 분할되면 많은 분할과 내부 절차의 수행을 필요로 하고, 이는 큰 코스트로 이어진다. 최악의 경우는 매 분할마다 한쪽이 empty array인 경우다. 이 경우, 하나의 원소만 정렬되므로, T(n) = T(n-1) + T(0) + O(n)과 같은 코스트가 발생하기 때문에, O(n^2) 수준의 poor한 performance를 보여준다.

조금 더 정확하게, T(n) = max(T(q) + T(n-q-1)) + O(n)인데, O(n^2)임은 substitution method를 통해 보일 수 있다. T(n) <= cn^2으로 잡고 직접 해보자. 물론 귀찮기 때문에 여기서 하진 않을 것이다. 

### Best-Case
반대로, completely-balanced한 경우는 가장 좋은 퍼포먼스를 보여주는 best-case일 것이다. 분할된 절반의 부분 배열에 대해 2회의 퀵 정렬을 재귀적으로 호출하므로, T(n) = 2T(n/2) + O(n)의 코스트가 발생하므로, T(n) = O(nlogn)의 performance를 보여준다.

### Average-Case
Average-case에선 어떨까? 사실, 특정 비율로의 분할은 결국 O(nlogn)의 복잡도로 귀결된다. 조금 나쁜 케이스로, 한 쪽은 반드시 1할이, 다른 쪽은 반드시 9할이 할당된다고 하면, T(n) = T(n/10) + T(9n/10) + O(n)의 코스트가 발생한다. 하지만 그럼에도 O(nlogn)이 된다. 즉, average-case도 O(nlogn)의 코스트를 발생시킬 것이란 사실을 우린 직관적으로 알 수 있다.

조금 더 자세히 알아보자. 우리는 worst-case에서 O(1)의 코스트를 발생시키는 partition이 최대 n회 수행됨을 알았다. X를 퀵 정렬에서 수행되는 comparison의 횟수라고 하면, 퀵 소트의 실행 시간은 O(n+X)가 되겠다.

여기서 중요한 점은, 피벗으로 선정된 원소는 다시는 피벗으로 선정되지 않는다는 점이다. 이로써 파티션 콜이 n번을 초과하지 않고, comparison의 대상이 되는 원소 쌍 {Zi, Zj}은 중복되지 않는다. i와 j의 비교가 발생하는 사건을 indicator, I로 나타내고, 비교 횟수를 X로 나타내어 보자.

Xij = I면, X = sum{i=1 to n-1}(sum{j=i+1 to n}(Xij))고, 이것의 expectation은 Xij가 발생할 확률의 합과 같다. 또, Xij가 발생하기 위해선, Zi 또는 Zj 둘 중 하나가 pivot으로 선정되어야 하기 때문에, P{Xij} = P{Zi 또는 Zj가 pivot으로 뽑힘} = 1/(j-1+1) + 1/(j-i+1) = 2/(j-i+1)고, 이를 sum으로 돌리면 O(nlogn)이 나온다. 물론 좀 드러워 보여서 계산은 하지 않았다.ㅎ

## Randomized Quicksort
고정 위치에 대해 pivot을 잡는다면, 나쁜 의도로 입력한 극단적인 input에 대해 최악의 performance를 보여줄 수 있다. 백준에서 정렬 문제에도 퀵 정렬을 쓰면 시간 초과로 틀리는 경우가 있는데, 가끔 그런 극단적인 인풋이 있기 때문이다. 우리는 여기에 randomization을 적용해서 이를 완화할 수 있는데, 두 방법이 있을 것이다.

- 배열 내의 pivot index를 임의로 정한다.
- 배열을 randomly permute한 다음 일반적인 퀵 정렬을 사용한다.

어차피 permutation은 주로 O(n)의 코스트를 발생시키므로, 퍼포먼스를 그렇게 악화시키진 않는다. 랜덤으로 pivot 위치를 결정하는 것도 퍼포먼스에 큰 영향을 주지 않는다.
















