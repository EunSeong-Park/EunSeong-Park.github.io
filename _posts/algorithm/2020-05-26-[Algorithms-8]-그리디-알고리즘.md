---
title: "[Algorithms 8] 그리디 알고리즘"
tags: Algorithms
toc: true
---

# Intro
우리는 지난 포스팅에서 DP와 그것의 예시를 알아보았다. 이번엔 그리디 알고리즘(greedy algorithm)에 대해 알아보자.

그리디 알고리즘은 locally optimal choice를 찾는 방식의 문제 해결법이다. 즉, 항상 완전한 최적해를 제공해주는 건 아니지만, 효율적인 방식으로 그것의 근사적인 해나 휴리스틱(heuristic)을 제공해 줄 수는 있다.


# Activity-Selection Problem
Activity-selection problem은 다음과 같은 상황을 다루는 문제다.

> 어떤 행사엔 여러 액티비티가 있고, 각 액티비티는 각자의 시작 및 종료 시간이 있다. 여기서 할 수 있는 최대의 액티비티 수를 알고 싶다.

![](/imgs/algorithm/algo27.png)

위와 같은 상황이라면, 최대 두 개의 활동을 할 수 있을 것이다. 이를 해결하기 위해, 다음과 같은 상황을 가정한다.

## Problem
$S=\{a_1, a_2, ..., a_n\}$을 액티비티의 집합으로 보고, 각 액티비티 $a_i$에 대하여 시작 시간과 종료 시간, $s_i < f_i$는 half-open interval($\[s_i, fi)$)이라 하자. 이러한 상황에서, "두 활동을 같이 할 수 있다"는 것은 다음을 의미한다.

$\[s_i, f_i) \cup \[s_j, f_j) = \emptyset$

주어지는 input은 종료 시간에 대해 정렬되어 있다고 가정한다. 즉,

$f_1 \le f_2 \le ... \le f_{n-1} \le f_n$

또, 아래와 같은 집합을 생각해보자.

$S_k = \{a_i \in S \vert f_k \le s_i \}$

이는 $a_k$가 종료된 이후 시작할 수 있는, 즉 $a_k$와 compatible하면서 시간적으로 뒤에 있는 $S$의 원소(액티비티)들의 집합을 의미한다.

## Solution
여기서 greedy choice라 함은... 

- 가장 빨리 끝나는 액티비티를 고른다. 동일한 종료 시간의 액티비티가 여러 개 있다면 아무거나 고른다.
- 그에 따라, $S$가 정렬되어 있다면, $a_1$부터 선택한다.

아하! 욕심쟁이라서 가장 눈 앞에 있는 최선의 선택, 즉 locally optimal choice을 하는구나! 라고 생각할 수 있겠다.

아무튼, $a_1$을 먼저 구했으니, 우리는 $S_1$에서 maximum set을 찾고, 이후에 이 과정을 반복하면 된다.

![](/imgs/algorithm/algo28.png)

위의 표를 예시로 하면, 그리디 알고리즘에서 최선의 선택은 아마, $1 \to 4 \to 8 \to 11$일 것이다.

## Implementation
그리디 알고리즘은 보통 하향식(top-down)으로 구현된다. 하향식, 그리고 재귀적 activity selector를 구현해보자.

![](/imgs/algorithm/algo30.png)

$s, f$는 $a_i$의 시작/종료 시간을 나타내는 배열이고, $k, n$은 배열의 시작과 끝 인덱스를 의미한다. 2-3에서 루프를 돌려 마지막 액티비티가 끝난 뒤에 시작하면서 가장 빨리 끝나는(이미 정렬됨을 가정하므로) 다음 액티비티를 찾는다. 그렇게 찾은 액티비티를 집합에 추가하면서 재귀적으로 찾아나간다.

Iterative한 selector를 구현해볼 수도 있다.

![](/imgs/algorithm/algo31.png)

## Cost
Recursive든 iterative든, 각 원소는 단 한 번 탐색된다. 따라서 $\Theta(n)$의 time complexity를 가진다. 다만, 이 알고리즘은 정렬을 필요로 하므로, 정렬되어 있지 않다면 $\Theta(n \log n)$의 비용이 추가로 발생한다.


# Use of Greedy Algorithm
그래서, 그리디 알고리즘을 언제 사용할 수 있을까? 그리디 알고리즘은 다음과 같은 상황에서 사용하기 좋다.

- Optimal substructure: 즉, 메인이 되는 문제의 optimal solution은 subproblem의 optimal solution을 포함한다. 이는 DP의 경우와 같다.
- Greedy-choice property: locally optimal choice의 결합이 globally optimal solution을 낳을 수 있다.

DP는 subproblem의 optimal solution에 근거하여 답을 선택하지만, 그리디 알고리즘은 subproblem을 풀기 전에 선택을 한다는 점에서 차이가 있다.


# Knapsack Problem

> 도둑은 가게를 털러 왔는데, 가게엔 $n$개의 물건이 있어 각 물건은 $a_i$로 나타내어진다. $a_i$엔 그에 대응되는 가격, $v_i$와 무게 $w_i$가 정해져있고, 도둑은 최대 $W$만큼의 무게까지만 들고 나갈 수 있다. 여기서 도둑은 적절히 물건을 골라, 최대로 돈을 벌고 싶다.

이 문제엔 두 가지 종류가 있다.

- 0-1 knapsack: 각 물건에 대하여, 도둑은 물건을 챙기거나(0) 두고 가는(1) 행위만 할 수 있다.
- Fractional knapsack: 각 물건에 대하여, 도둑은 물건의 일부만을 챙겨갈 수 있다. 가격은 가져간 물건의 양에 정비례한다.

Fractional한 문제가 좀 더 쉬운데, 무게 대비 비싼 순서로 정렬한 뒤, 앞에서부터 담으면 되기 때문이다. 이는 그리디 알고리즘으로 구현할 수 있다. 정렬에 $O(n\log{n})$을, 이후에 $O(n)$을 소비한다.

![](/imgs/algorithm/algo32.png)

다만, 그리디 알고리즘은 0-1 Knapsack에선 최적의 솔루션을 제공하지 못한다. 다음과 같은 반례가 있다.

![](/imgs/algorithm/algo33.png)

0-1 Knapsack은 DP를 이용해 해결하도록 하자.


# Huffman Codes
__허프만 코드(Huffman code)__ 는 데이터 압축(data compression)을 위한 부호화 방식 중 하나다. "자주 쓰이는 코드를 짧게 만든다"가 허프만 코드의 메인 아이디어다.

우리는 주어진 문자열을 가장 짧은 길이의 코드(0, 1) 길이로 부호화를 하고 싶다. 최적의 데이터 압축을 위한 방법과, 고려해야 할 사항들을 하나하나 살펴보자.

## Code Types
문자열은 다양한 방식으로 인코딩될 수 있다.

- Fixed length code: 모든 코드의 길이가 동일하다. ASCII가 모든 단일 문자에 대해 8비트를 사용하는 것이 그 예시다. Variable length code와 반대 개념이다.
- Prefix code: Prefix free code라고도 한다. 어느 코드도 다른 코드의 접두어(prefix)가 되지 않아, 주어진 문자열에 대해 유일한 디코딩을 제공한다.

허프만 코드는 가변 길이 코드이자 접두어 코드다.

## Definition
아래와 같이 정의를 내리고 시작하자.

- $X$: 문자(character)의 집합.
- $C: X \arrow \{0, 1\}^{* } $: 코드. 이는 아래와 같이 확정할 수 있다.
  - $C: X^{* } \arrow \{0, 1\}^{* }$, $C(x_1 ... x_n) = C(x_1)...C(x_n)$

그리고 복호화(decode)를 가능케 하기 위해, 우리는 문자열과 코드 간 일대일 대응이 이루어져야 한다. 달리 말하면, 같은 코드로 부호화되는 문자열이 없어야 한다.

for any $s, t \in X^{* }$, if $C(s) = C(t)$ then $s=t$

$X$를 문자들의 확률 분포(probability distribution)라 하고, 그에 따라 각 문자열 $x$의 등장 확률을 $p(x)$라 한다. 

## Example
허프만 코드를 위한 알고리즘을 다루기 전, 인코딩과 디코딩 과정을 예시를 통해 간단히 살펴보자. 다음과 같은 상황을 가정한다.

- $X = \{ e, a, t \}$
- $C(e) = 0, C(a) = 10, C(t) =11$

이러한 코드는 분명 접두어 코드다. 그 어느 것도 다른 코드의 접두어가 되지 않는다. "ate"를 인코딩하면, "10110"이고, 이를 다시 디코딩하면 "ate"로 유일하게 결정된다. 우리가 원하는 케이스다.

- $C(e) = 0, C(a) = 10, C(t) =101$

반면 위와 같은 코드의 경우, "a"가 "t"의 접두어가 된다. "ate"를 인코딩하면 101010이 나오는데, 이는 "aaa"로도, "tea"로도, "ate"로도 디코딩이 될 수 있다.

## Optimal Prefix Code
최적의 코드라면, 다음을 만족해야 할 것이다.

- 유일하게 디코딩된다.
- $E(\vert C(x) \vert)$ $=\sum p(x) \vert C(x) \vert$, 즉 평균 코드 길이가 최소가 되도록 한다.

우리는 "접두어 코드 중에 항상 최적의 코드가 존재한다"는 사실에 기반해, 접두어 코드에만 집중하도록 한다. 접두어 코드를 사용해야 디코딩이 직관적이고 용이해지기 때문이다.

우리는 이진 트리(binary tree)를 이용해 접두어 코드를 설계할 수 있다. 루트에서 시작하여, 앞에서부터 코드를 읽으며 리프까지 내려간다. 루트에서 리프까지 거쳐온 노드가 그 문자의 코드를 결정한다.

![](/imgs/algorithm/algo34.png)

위 그림은 고정 길이와 가변 길이 코드(이면서 접두어 코드)를 이진 트리로 작성한 예시다. 당연하게도, 고정 길이 코드는 접두어 코드다. 길이가 같으니 어떤 코드도 다른 코드의 접두어가 될 수 없다.

이러한 관점에서 보면, 루트에서 리프로의 경로 길이(즉, 깊이(depth))의 기댓값이 가장 작은 코드가 최적의 코드라고 할 수 있겠다. 좀 더 깔끔하게 표현하면, 어떤 문자열을 접두어 코드 이진 트리 $T$를 이용해 인코딩하려면, 그것의 비용, $B(T)$는...

$B(T) = \sum_{x \in X} x.\text{freq} * \text{depth}(x)$

### Constructing Optimal Code
먼저, __최적의 접두어 코드로 만들어지는 이진 트리는 full binary tree여야 한다.__ 여기서 full하다는 것은, 모든 내부 노드(internal node)가 두 자식을 가짐을 의미한다. 왜냐? 간단히 non-full한 이진 트리는 최적의 접두어 코드가 아니기 때문이다. 이는 non-full 트리가 최적임을 가정하고 귀류법을 이용하여 증명할 수 있다.

![](/imgs/algorithm/algo35.png)

위 그림만 봐도 왜 non-full이 최적이 되지 못하는지 알 수 있을 것이다.

또, 위의 인코딩 비용, $B(T)$의 정의에 의하면, 출현 빈도가 낮은 문자열에 큰 깊이를 할당하는 게 합리적으로 보인다. 그러면, 빈도가 가장 낮은 문자열을 먼저 묶어 트리를 형성하면서 이를 상향식으로 쌓아 올리면, 빈도가 가장 낮은 문자열이 아래에, 가장 높은 문자열이 위에 올라올 것이다.

![](/imgs/algorithm/algo36.png)

### Pseudocode

![](/imgs/algorithm/algo37.png)

우리는 빈도를 key로 여겨, 이진 최소 힙(min-heap)를 이용해 우리가 원하는 형태의 이진 트리를 만들 수 있다. 위의 그림과 코드를 같이 보면, 그 작동 원리가 잘 이해될 것이다.

### Cost
최소 힙을 세우기 위해 $O(n)$이, 매 extraction과 insertion에 $O(\log{n})$의 비용이 발생한다. 즉,

$O(n) + (n-1)O(\log{n}) = O(n \log{n})$

## Greedy Algorithm
이렇게 구현한 허프만 코드는 그리디 알고리즘의 특성을 띤다. 왜?

- 매 서브트리를 구성하는 과정에서 지역적으로 최적의 선택을 한다. 남은 문자열(혹은 서브트리)에서 가장 빈도가 낮은 두 대상만을 고르기 때문이다. 
- 최적의 코드는 optimal substructure를 가진다. 즉, 어떤 최적 코드 이진 트리는 그것의 서브트리 또한 최적 코드를 가진다.
