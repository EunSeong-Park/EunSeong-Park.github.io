---
title: "[Data Science Programming 5] EDA by Pandas"
tags: Data-Science Statistics Python
toc: true
---

# Intro
통계학(statistics)은 어떤 샘플로부터 모집단에 대한 여러 유용한 성질을 이끌어내는 학문이다. 이는 크게 두 branch로 나눌 수 있다.

- **Descriptive Statistics**: 주어진 데이터를 통해 그 샘플의 특성을 정량적으로 기술한다.
- **Inferential Statistics**: 주어진 데이터를 통해 그 샘플이 유래한 모집단의 특성을 추론한다.

보통 모집단의 정량적 특성을 **parameter**, 샘플의 정량적 특성을 **statistic**이라고 한다.

아무튼 여기서 우리는 전자를 중점적으로 알아볼 것이고, 이를 위한 **EDA(Exploratory Data Analysis)**를 해볼 예정이다. 또, EDA를 위해 **Pandas**라는 Python 라이브러리를 사용해보자.



# Pandas
**Pandas**는 데이터 조작과 분석을 용이하게 해주는 Python 라이브러리다. Numpy와 아주 잘 호환되고, CSV, Excel, text 등 여러 종류의 데이터를 쉽게 다룰 수 있도록 한다.

일단 import해보자.
```python
import pandas as pd
```

## DataFrame
`pandas.DataFrame`은 Pandas에서 사용되는 가장 기본적이고 중요한 자료형이다. 단어 그대로 데이터를 구조화시킨 프레임인데, 이는 Pandas에서 제공하는 많은 도구들을 사용하는 데 최적화되어있다.

먼저, 데이터 프레임을 선언해보자.

```python
# 기본 선언 방식
my_df = pd.DataFrame([[1,2,3],[4,5,6],[7,8,9]],columns=["A","B","C"],index=["a","b","c"])
print(my_df)
'''
   A  B  C
a  1  2  3
b  4  5  6
c  7  8  9
'''

# columns와 index는 생략 가능하다. 생략 시 0, 1, 2, ... 순으로 이름이 할당된다.
my_df = pd.DataFrame([[1,2,3],[4,5,6],[7,8,9]])
print(my_df)
'''
   0  1  2
0  1  2  3
1  4  5  6
2  7  8  9
'''

# 빈 데이터 프레임을 만들 수도 있다.
my_df = pd.DataFrame()
print(my_df)
'''
Empty DataFrame
Columns: []
Index: []
'''

# (column_name - column_tuple) 쌍의 딕셔너리를 이용해 선언할 수도 있다.
my_dict = {"A": (1,2,3,4,5), "B": (10,20,30,40,50), "C": (100,200,300,400,500)}
my_df = pd.DataFrame(my_dict, index=["a", "b", "c", "d", "e"])
print(my_df)
'''
   A   B    C
a  1  10  100
b  2  20  200
c  3  30  300
d  4  40  400
e  5  50  500
'''
```

## Basic Operations
마지막 데이터 프레임을 예시로 계속 사용할 예정이다.

```python
'''
   A   B    C
a  1  10  100
b  2  20  200
c  3  30  300
d  4  40  400
e  5  50  500
'''
```

### Rename
`rename()` 메소드는 행이나 열의 이름을 바꾸어, 그 결과를 리턴한다. 복사본을 바꾸므로 **원본을 조작하지는 않는다**.

```python
print(my_df.rename(columns = {"A":"AA", "B": "BB"}, index= {'a': 'aaa'}))
'''
     AA  BB    C
aaa   1  10  100
b     2  20  200
c     3  30  300
d     4  40  400
e     5  50  500
'''
```

위에서 볼 수 있듯, 변경할 행/열에 대한 매핑을 정의해주면 된다. 변경할 행/열이 없으면 생략해도 괜찮다.

### Index
특정 행이나 열, 원소를 인덱스할 수 있다.

```python
# Column
print(my_df["A"])
'''
a    1
b    2
c    3
d    4
e    5
Name: A, dtype: int64
'''

# Index: key
print(my_df.loc["b"])
'''
A      2
B     20
C    200
Name: b, dtype: int64
'''

# Index: index
print(my_df.iloc[1])
'''
A      2
B     20
C    200
Name: b, dtype: int64
'''
```

물론, 특정 원소를 인덱스할 수도 있다.
```python
print(my_df.loc["a", "A"])   # 1
print(my_df["A"]["a"])       # 1
print(my_df["A"].iloc[0])    # 1
print(my_df.iloc[0,0])       # 1
```

여기서 알 수 있듯, `iloc`과 `loc`은 index-major하고, 일반적인 key를 이용한 인덱스 방법은 column-major하다. 너무 러프한 설명이지만, 아무튼 대충 그렇다!

이런 것들도 가능하다.

```python
print(my_df["A"].iloc[0:2])
'''
a    1
b    2
Name: A, dtype: int64
'''

print(my_df["A"].loc["a","b"])
'''
a    1
b    2
Name: A, dtype: int64
'''
```

### Insertion / Modification
내부 정보를 간단히 변경하거나 삽입할 수 있다. 딕셔너리와 비슷하게 동작한다.
```python
my_df["D"] = (1000,2000,3000,4000,5000)
print(my_df)
'''
   A   B    C     D
a  1  10  100  1000
b  2  20  200  2000
c  3  30  300  3000
d  4  40  400  4000
e  5  50  500  5000
''''

my_df["D"]["e"] = 50000
print(my_df)
'''
   A   B    C      D
a  1  10  100   1000
b  2  20  200   2000
c  3  30  300   3000
d  4  40  400   4000
e  5  50  500  50000
'''

my_df["D"] = 1000
'''
   A   B    C     D
a  1  10  100  1000
b  2  20  200  1000
c  3  30  300  1000
d  4  40  400  1000
e  5  50  500  1000
'''
```

### Filter
행, 열, 혹은 데이터 프레임 전체에 조건을 걸어 `bool`로 구성된 데이터 프레임을 만들 수 있다. 이를 이용해 인덱싱도 할 수 있다!

```python
print(my_df > 200)
'''
       A      B      C     D
a  False  False  False  True
b  False  False  False  True
c  False  False   True  True
d  False  False   True  True
e  False  False   True  True
'''

print(my_df[my_df["C"] > 200])
'''
   A   B    C     D
c  3  30  300  1000
d  4  40  400  1000
e  5  50  500  1000
'''

print(my_df.loc["c"] > 200)
'''
A    False
B    False
C     True
D     True
Name: c, dtype: bool
'''

```

### Etc.
기타 몇 가지 메소드를 더 알아보자.

```python
my_long_data = pd.DataFrame([[1,2,3,4,5] for i in range(100)], 
                            columns = ["One", "Two", "Three", "Four", "Five"])

# 긴 데이터는 짤려서 나온다.
print(my_long_data)
'''
    One  Two  Three  Four  Five
0     1    2      3     4     5
1     1    2      3     4     5
2     1    2      3     4     5
3     1    2      3     4     5
4     1    2      3     4     5
..  ...  ...    ...   ...   ...
95    1    2      3     4     5
96    1    2      3     4     5
97    1    2      3     4     5
98    1    2      3     4     5
99    1    2      3     4     5

[100 rows x 5 columns]
'''

# 데이터 앞쪽 / 뒤쪽을 리턴.
print(my_long_data.head())
'''
   One  Two  Three  Four  Five
0    1    2      3     4     5
1    1    2      3     4     5
2    1    2      3     4     5
3    1    2      3     4     5
4    1    2      3     4     5
'''
print(my_long_data.tail())
'''
    One  Two  Three  Four  Five
95    1    2      3     4     5
96    1    2      3     4     5
97    1    2      3     4     5
98    1    2      3     4     5
99    1    2      3     4     5
'''

print(my_long_data.shape) # (100, 5)

```



## Read Data
앞서 언급하였듯, Pandas는 외부 데이터를 가져와 조작 분석하기 용이하다. 보통 CSV, Excel, 혹은 그냥 텍스트 파일(`.txt`)를 쓰는데, 이들을 데이터 프레임에 로드하는 방법을 알아보자.

```python
# CSV
my_data = pd.read_csv("./data.csv", header=0) # 헤더가 없다면 header=None을 사용하자

# Excel
my_data = pd.read_excel("./data.xlsx", sheet_name="Sheet 1")

# Text
my_data = pd.read_table("./data.txt")
```


# EDA
**EDA(Exploratory Data Analysis)**란, 샘플(혹은 데이터)의 정량적 특성과 변수들을 탐색하고 정리하는 과정을 의미한다. 주어진 데이터에 대해, 일반적으로 다음과 같은 것들을 생각해볼 수 있다.

우선, 주어진 데이터에 대해,

- 범주화될 수 있는가? **(categorical)**
  - 그 범주는 nominal한가, ordinal한가?
- 정량적인가? **(quantitative)**
  - 이산적인가, 연속적인가?

그리고 데이터의 특성에 대해,

- **Central tendency**: 데이터 분포의 중심을 나타내기 위한 대푯값. (mode, mean, median)
- **Variation**: 데이터의 변동성의 정도. (standard deviation, entropy)
- **Covariation**: 두 데이터 그룹 간의 연관성. (covariance, correlation coefficient)
- **Outliers**, **Missing Values**, etc.

그래서 이걸 어떻게 알아내냐? Pandas로!

## EDA in Pandas
여기서부턴 다음과 같은 데이터 프레임을 사용할 것이다. 당연하게도, 랜덤이니 결과가 다를 수 있다.

```python
mydat = pd.DataFrame(np.random.rand(1000,5), columns=["A", "B", "C", "D", "E"])
'''
            A         B         C         D         E
0    0.815318  0.833773  0.651665  0.664459  0.723556
1    0.593693  0.473671  0.172573  0.084455  0.420551
2    0.938062  0.895502  0.317270  0.462460  0.699711
3    0.342599  0.272372  0.011059  0.146101  0.375777
4    0.048698  0.391240  0.242988  0.304109  0.084059
..        ...       ...       ...       ...       ...
995  0.075563  0.428630  0.585738  0.935963  0.619812
996  0.721611  0.641447  0.835852  0.831499  0.387838
997  0.341536  0.919988  0.357218  0.804045  0.369225
998  0.809606  0.130916  0.084933  0.863121  0.028719
999  0.176882  0.195506  0.641040  0.980688  0.815070

[1000 rows x 5 columns]
'''
```

가장 기본적으로, `describe()` 메소드는 각 열의 데이터에 대한 전반적인 정보를 데이터 프레임 형태로 보여준다. 데이터 수(`count`), 평균(`mean`), 표준 편차(`std`), 그리고 5-number summary까지 표시된다!

```python
print(mydat.describe)
'''
                 A            B            C            D            E
count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000
mean      0.507093     0.494154     0.495172     0.486350     0.516875
std       0.289324     0.289650     0.280336     0.292908     0.285604
min       0.000145     0.000075     0.000152     0.003454     0.000162
25%       0.258094     0.228341     0.258661     0.227314     0.276009
50%       0.501479     0.493360     0.499277     0.479919     0.507345
75%       0.760825     0.742261     0.732034     0.751625     0.769683
max       0.999442     0.998142     0.997796     0.998940     0.997723
'''
```

개별적으로, 그리고 조금 더 다양한 정보를 확인해볼까?

결과 복붙하기가 귀찮아서 가능하면 특정 열에만 메소드를 적용할 것이지만, 대부분 데이터 프레임 전체에도 적용된다. 이 경우, 주어진 열마다 메소드가 적용되어, 하나의 series를 형성한다.

```python

print(mydat["A"].mean()) # mean
print(mydat["A"].var())  # var
print(mydat["A"].std())  # standard deviation

print(mydat["A"].min())         # min  
print(mydat["A"].max())         # max
print(mydat["A"].quantile(0.5)) # percentage quantile

print(mydat.cov()) # Covariance
'''
          A         B         C         D         E
A  0.083708  0.001262  0.000443 -0.001081  0.000039
B  0.001262  0.083897 -0.001078 -0.000325  0.000634
C  0.000443 -0.001078  0.078588 -0.002395  0.000821
D -0.001081 -0.000325 -0.002395  0.085795 -0.000464
E  0.000039  0.000634  0.000821 -0.000464  0.081569
'''

print(mydat.corr()) # Correlation coefficient
'''
          A         B         C         D         E
A  1.000000  0.015057  0.005458 -0.012757  0.000476
B  0.015057  1.000000 -0.013271 -0.003827  0.007661
C  0.005458 -0.013271  1.000000 -0.029169  0.010253
D -0.012757 -0.003827 -0.029169  1.000000 -0.005545
E  0.000476  0.007661  0.010253 -0.005545  1.000000
'''
```

이정도면 충분히 Pandas를 써봤다고 할 수 있겠다. 각 메소드의 디테일은 공식 문서를 보는 게 가장 베스트다. 알아서 공부하자.

아무튼 다음엔 이렇게 얻은 데이터를 시각화해볼 것이다. **Matplotlib**과 **Seaborn** 으로!!