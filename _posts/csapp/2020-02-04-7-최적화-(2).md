---
title:  "7 최적화 (2)"
toc: true
tags: CS:APP
---

# Intro
지난 시간엔 컴파일러에 의해 이루어지는 최적에 대해 간단히 알아보았고, 이번엔 code-level에서 할 수 있는 최적화 기법 몇 가지를 공부해보려 한다. 책에선 예시를 통해 하나의 코드를 단계적으로 최적화시키며 진도를 나갔지만, 이번엔 개념만 알아보고 별도의 예시를 구상해보기로 했다. 너무 책을 받아 적는 느낌이 나서... 또, 책 내용뿐만 아니라 각 단락에 관련된 내용이 생각나면 함께 적어보려고 노력했다.


# 루프 최적화
대부분의 프로그램에서 루프를 사용하는데, 어떤 루프는 많이 사용되거나 속도/리소스가 매우 중요한 문제여서 최적화가 절실할 수 있다. 루프 자체의 알고리즘도 중요하지만, 시스템 또는 프로세서의 특성을 앎으로써 그 성능을 더욱 개선할 수 있다.

## 카운터 및 종료 조건 최적화
0에서 n으로 가는 루프보단, n에서 0으로 down-count하는 루프의 성능이 더 좋다. 왜냐? 전자의 경우 컴파일러는 counter, i와 최종값 n을 비교할 때, `i < n` 의 연산을 위해 n을 저장할 레지스터를 하나 더 할당해야 한다. 하지만 후자의 경우, 반복 시마다 i가 non-zero인지만 체크해주면 되므로 cost가 전자보다 덜하다. 

## do-while문의 사용
어떤 루프가 한 번 이상은 실행됨이 보장되었다면, for문보다는 do-while을 쓰는 게 바람직하다. 컴파일러가 counter가 non-zero 여부를 체크할 필요가 없어지고, if 등에 의한 조건분기는 cache가 작동하는 방식을 생각하면 cost가 상당히 줄어들 수 있다. 이 부분은 cache 부분을 배울 때 다시 생각해보자.

## 루프 언롤링 Loop Unrolling
루프 언롤링은 루프 내 연산 수가 적은 루프에 대하여, 매 루프마다의 연산량을 늘림으로써 루프 자체의 반복 수를 줄이는 기법이다. 우선 러프한 예시로 알아보자.

    int i;
    int sum = 0;
    for (i=0; i < 1000; i++)
        sum += i;

이것을

    int i;
    int sum = 0;
    for (i=0; i < 1000; i+=4){
        sum += i + 0;
        sum += i + 1;
        sum += i + 2;
        sum += i + 3;
    }
        
로 변환한다고 볼 수 있다. 이러한 변환은 겉보기엔 코드가 길어지고, 비효율적일 것으로 보인다. (일부는 맞다.) 그러나

1. 루프의 인덱스나 조건분기 등과 같이 프로그램 자체와 직접적인 관련이 없는 연산을 줄인다. 즉, 오버헤드를 줄일 수 있다.
2. 전체 연산 수를 줄이는, 추가적인 최적화를 할 수 있는 형태로 만들어진다.

다만, 위에서도 볼 수 있듯, 루프 언롤링은 코드의 크기를 증가시키고 가독성을 떨어뜨릴뿐 아니라, 과도한 레지스터 할당으로 오히려 성능을 저하시킬 수 있다. 언롤링을 크게 할수록 오버헤드는 줄어들지만, 다른 부분에서 성능 저하를 일으키는 것이다. 코딩 시 그 둘 사이에서 적절한 타협점을 찾아야 하고, 루프 언롤링은 컴파일러에 의해 이루어질 수도 있기 때문에 (GCC의 경우 -O3 이상) 의도치 않은 충돌이 일어나지 않도록 주의해야 한다.


# 병렬성 향상
일반적으로 프로그램이 작동하는 일련의 과정을 순차적으로 생각하여 다루지만, 오늘날의 프로세서는 작업을 병렬적으로 처리할 수 있다. 이를 parallelism(병렬성)이라 하며, 그 종류로 instruction 간의 독립성을 따지는 Instruction-Level Parallelism과 병렬적 실행을 위한 하드웨어적 능력을 따지는 H/W Parallelism이 있다.

Parallelism은 다양한 요인에 의해 향상되고 저하될 수 있다. 프로세서를 이해하는 것은 Parallelism을 향상시키고 performance를 증가시키는 큰 기회가 될 것이다.

## Superscalar Processor
복수의 instruction을 한 사이클에 처리하는 프로세서를 의미한다. 필요한 동작들이 파이프라인화되어 매 사이클마다 새로운 연산을 수행하고, 어떤 연산은 복수의 유닛들에 의해 수행되어 그 속도를 증대시킬 수 있다. 예시로 곱셈을 세 번 수행하는 어떤 함수 mult에 대해 알아보자.

    long mult(long a, long b, long c){
        long p1 = a*b;
        long p2 = a*c;
        long p3 = p1*p2;
        return p3;
    }

미리 알아두자면, integer multiply는 3 cycle을 필요로 한다. 만약 순차적으로 연산이 이루어진다면, 저 세 개의 곱셈에 대하여 최소 9 cycle이 소요될 것이다. 하지만,

![](/imgs/csapp/17.png)

위와 같이 부분적인 계산들을 다음 stage로 넘기며 병렬적으로 계산을 수행하면 7 cycle로 계산이 끝난다. 이처럼 parallelism은 성능 및 속도를 높이는 중요한 포인트가 될 수 있다.

## Data Dependence
하드웨어적 성능이 충분하더라도, instruction들이 충분히 병렬적이지 못하다면 그 자원을 온전히 사용할 수 없다. 즉, 병렬성이 떨어지게 된다. 병렬성 저하의 여러 원인이 있지만, 그 중 data dependence에 대해서만 간단히 알아보려고 한다.

### Flow Dependence
어떤 instruction은 계산을 위해 앞에 있는 어떤 instruction의 결과를 필요로 할 수 있다. 이는 instruction이 앞 명령의 종료에 후행되어야 함을 의미하므로 병렬성을 저해하게 된다. 위에서 본 mult 함수 중 p3이 바로 그 예시다. p3을 계산하기 위해선 p1, p2의 값을 알아야 하므로 앞의 연산이 모두 끝나기 전까지 기다려야 한다.

### Antidependence
아래의 예시를 보자.

    addq   %r1, %r2
    imulq  %r3, %r1
    
이 경우, flow dependence는 없지만, 순서를 바꾸게 될 경우 `addq`에서 읽힐 %r1의 값이 달라질 수 있으므로, 그 순서를 바꿀 수 없다. 이러한 경우를 antidependence라 한다.

### Output Dependence
아래의 예시를 보자.

    movq  $3, %r1
    addq  %r1, %r3
    movq  $5, %r1
    
만약 첫 번째와 세 번째가 동시에 실행되거나 순서가 바뀐다면 %r3의 결과가 달라질 것이다. 이렇게 두 instruction의 결과가 동일한 dest에 저장되는 경우를 output dependence라 한다.

## Reassociation Transform
정수 덧셈 혹은 곱셈은 교환법칙 및 결합법칙이 성립한다. 그로 인해 임의로 여러 피연산자들을 묶거나 그 위치를 바꿀 수 있다. `(((((a + b) + c) + d) + e) + f)` 를 순차적으로 계산하기 위해선 총 5 cycle이 걸리겠지만, `(a + b) + ((c + d) + f)`로 변환하면 병렬적으로 계산이 가능하여 3 cycle 정도면 계산이 완료될 것이다.

앞의 식과 뒤 식의 차이점은 무엇이었을까? 바로 flow dependence에 있었다. 앞 식은 매 다음 연산이 전 연산의 결과를 필요로 하여 병렬성이 전무했고, 뒤 식은 `(c + d) + f`와 최종 연산만이 dependence가 존재했다. 이렇게 식, 또는 코드를 변환하여 병렬성을 향상시키는 방법을 Reassociation Transform(재결합 변환)이라 한다.

## Separate Accumulator
아래 러프한 예시를 보자.
    
    /* example 1 */
    int acc = 0;
    for (int i=0; i < 1000; i++)
        acc = acc + a[i];
    
    /* example 2 */
    int acc = 0;
    for (int i=0; i < 1000; i+=2){
        acc = acc + a[i];
        acc = acc + a[i+1];
    }
        
    /* example 3 */
    int acc1 = 0;
    int acc2 = 0;
    for (int i=0; i < 1000; i+=2){
        acc1 = acc1 + a[i];
        acc2 = acc2 + a[i+1];
    }
    int acc = acc1 + acc2;
    
2번은 1번을 루프 언롤링한 것을, 3번은 2번에 2개의 누산기(Accumulator)를 적용한 결과다. 언롤링된 루프는 다수의 누산기에 의해 병렬성이 더욱 확보되어 높은 performance를 이끌어낼 수 있다.  
                

간단하고 명확한 예시를 생각해내고 싶었는데 잠은 오고 딱히 떠오르는 아이디어도 없어서 내가 생각하기에도 구린 예시만을 뱉은 것 같다. 그냥 책 예시를 처음부터 쓸 걸 그랬다. 말이 러프지 그냥 똥이다. 아무튼 다음 시간엔 6단원인 Memory Hierarchy에 들어갈 예정이다.

