---
layout: post
title:  "6 최적화 (1)"
date:   2020-02-02
author: Eunseong Park
categories: CS:APP
---

# Intro
최적화는 굉장히 중요하고, 그런 만큼 능숙하고 효과적으로 해낼 수 있어야 한다. 또, 어떤 코딩 방법이 그 자체로 효율적인 최적화를 이끌어내며, 컴파일러로 하여금 효과적인 최적화를 시킬 수 있는지 아는 것도 중요하다. 그럼에도 개발의 과정에선 최적화와 어느 정도의 readibility 사이에서의 적절한 타협이 필요하고, 프로그램의 원래 목적에 맞는, 정확한 동작을 유지해야 한다. 

결국 최적화와 그로부터 비롯된 높은 수준의 performance는 단순히 알고리즘뿐 아니라 컴파일러, 혹은 시스템에 대한 이해까지 필요한 셈이다. 아무튼 이번 시간엔 컴파일러 관점에서의 최적화를 중심으로 알아보자.


# 컴파일러의 최적화
코드 작성자뿐만 아니라 컴파일러도 최적화 작업을 해낸다. 컴파일러는 program to machine의 mapping으로도 볼 수 있는데, 그렇기에 프로그램(코드)과 시스템 양쪽 모두의 측면에서 최적화를 진행한다. 전자의 경우 무의미한 코드의 삭제, 계산 수식의 단순화 등을 예로 들 수 있고, 후자의 경우 레지스터 및 메모리 할당 등에서의 최적화를 예시로 들 수 있겠다.

또한, 대부분의 컴파일러는 최적화 수준의 설정 및 제어 기능을 제공한다. 가령 GCC의 경우, 최적화 옵션 플래그(-Og, -O1, -O2, ...)를 지정함으로써 서로 다른 수준의 최적화를 제공한다. 높은 최적화 수준은 광범위한 최적화를 통해 보다 큰 성능 개선을 이끌어낼 수 있으나, 프로그램의 크기가 커지거나, 프로그램이 근본적으로 변하거나, 디버깅 도구를 통한 디버깅이 어려워질 수 있다는 단점이 있다. 

이제, 컴파일러에 의한 최적화가 일반적으로 어떤 특징을 가지는지 알아보자.

## 컴파일러 최적화의 특징

1. 프로그램의 동작이 바뀌지 않을 수준에서의 안전한 최적화만을 진행한다. 최적화 수준에 상관없이, 최적화 후에도 프로그램의 동작은 일치해야 한다.
2. 대부분의 경우, 프로시저 단위 내에서만 분석을 수행한다. 대개 프로그램 전체에 대한 분석은 그 cost가 크기 때문이다. 최신 컴파일러는 inter-procedural analysis를 지원하기도 하지만, 그래도 아직 서로 다른 파일 간의 분석까지는 수행하지 못한다.
3. 대부분의 분석은 static한 정보에 의존하여, run-time input을 고려하는 덴 어려움이 있다.
4. 대부분 asymptotic efficiency(big-O 등으로 나타내어지는)까지 개선하지는 못한다. 즉, 적절한 알고리즘을 선택해 이를 개선하는 것은 프로그래머에게 달려있는 셈이다.

아마 1번 특징이 가장 핵심적인 부분이 아닐까 싶다. '안전함'의 범위를 프로그래머가 잘 캐치해내지 못하면, 컴파일러의 최적화를 망칠 수 있다. 이 문제는 조금 뒤에 더 자세히 다루어보자.

## 컴파일러 최적화의 예시
앞서 말했듯, 컴파일러는 코드뿐 아니라, 프로세서를 비롯한 시스템도 고려해야 한다. 또, 컴파일러마다 최적화의 범위, 방식, 수준 모두 다를 것이다. 그럼에도 어느 정도 general한 최적화들이 있는데, 이를 가볍게 살펴보고 컴파일러 최적화가 어떻게 일어나는지 확인해보자.

    for (long j = 0; j < n; j++)
        a[n*i+j] = b[j];

위 코드의 문제는 무엇일까? a의 인덱스 중, n*i는 루프를 돌아도 변하지 않는데, 위 코드에서는 n*i를 매 루프마다 계산해야 한다. 하지만 컴파일러는 이를 찾아내 최적화할 수 있다. 아래 최적화된 Assembly를 확인해보자.

    loop_example:
        testq   %rcx, %rcx               # n이 non-zero인지 검사
        jle     .L1                      # 0인 경우 바로 return
        imulq   %rcx, %rdx               # %rdx = n*i
        leaq    (%rdi, %rdx, 8), %rdx    # rowp = A + %rdx * 8
        movl    $0, %eax                 # j = 0
    .L3:
        movsd   (%rsi, %rax, 8), %xmm0   # t = b[j]
        movsd   %xmm0, (%rdx, %rax, 8)   # M[A+ni*8 + j*8] = t
        ...

세 번째 instruction에서 n과 i를 곱한 것을 확인할 수 있다. 즉, 원래 코드와 달리 n\*i의 계산이 루프 밖으로 빠져나와 있다. 최적화된 결과를 C로 다시 옮기면 대강 이렇다.

    long j;
    long ni = n*i;
    double *rowp = a+ni;
    for (j = 0; j < n; j++)
        *rowp++ = b[j];

또, cost가 큰 계산을 결과가 같은 다른 계산으로 치환하기도 한다. 곱셈, 나눗셈을 bit shift로 바꾸는 게 대표적이다.

    16*x <=> x << 4
    
같은 수나 대상을 지정하는 expression이 있다면, 계산의 반복을 피하기 위해 재사용할 수도 있다.

    /* before */
    up =    val[(i-1)*n + j  ];
    down =  val[(i+1)*n + j  ];
    left =  val[i*n     + j-1];
    right = val[i*n     + j+1]; 
    
    /*optimized*/
    long inj = i*n + j;
    up =    val[inj - n];
    down =  val[inj + n];
    left =  val[inj - 1];
    right = val[inj + 1];

그 외에도 최적화의 방법이 여럿 있는데, 더 궁금하면 책을 찾아보도록 하자.

## Optimization Blocker
어떤 상황이나 요소는 컴파일러의 최적화를 막는다. 이런 경우, (코드 수준에서) 직접 최적화를 수행하거나, 컴파일러가 최적화를 할 수 있도록 그 요인을 제거 또는 수정해야 한다.

### Procedure call
컴파일러는 프로시저 호출 명령 근처에서 보다 약한 최적화를 수행한다. interprocedural한 최적화가 아니라면 프로시저 호출로 인한 영향을 알 수 없기 때문이다. 아래 예시를 보자.
    
    void lower(char *s)
    {
        size_t i;
        for (i = 0; i < strlen(s); i++)
          if (s[i] >= 'A' && s[i] <= 'Z')
            s[i] -= ('A' - 'a')
    }
    
input string을 소문자로 변환하는 함수다. 동일한 argument s에 대해 strlen을 불필요하게 반복적으로 호출하는데, 놀랍게도 (위 예시에서는 루프 밖으로 보내는 최적화를 할 수 있었음에도) 이 경우에는 최적화가 일어나지 않는다. 어째서일까? 프로시저의 호출이 global state에 영향을 주는 side-effect를 유발할 수 있고, 상황에 따라 같은 argument임에도 다른 값을 리턴할 수도 있기 때문이다. 

### Memory Aliasing
Memory aliasing은 두 개의 포인터가 같은 대상(메모리 위치)을 가리키는 경우를 의미한다. 프로그래머가 의도하지 않은 aliasing의 가능성을 열어, 예상 외의 결과를 만들어낼 수 있다.

예시로 아래의 함수들을 보자. argument x, y에 대해, x값을 y의 두 배로 변경하는 함수다.

    void doubling(long *x, long *y){
        *x += *y;
        *x += *y;
    }

    void doubling2(long *x, long *y){
        *x += 2 * *y;
    }
    
겉보기엔 두 함수 모두 의도대로 잘 동작할 것으로 보인다.

메모리 참조 횟수의 측면에서 보면 doubling2 함수가 그 수가 훨씬 적어 보이고, 실제로도 그렇다. doubling 함수는 총 6회(read x -> read y -> write x의 2회 반복), doubling 함수는 총 3회(read x -> read y -> write x)다. 그렇다면 컴파일러는 doubling을 최적화 할 때 결과가 __ 같아 보이는__ doubling2 함수와 같은 방식으로 만들 것 같다. 

하지만 컴파일러는 doubling에 대해 최적화를 수행하지 않는데, 이는 컴파일러가 memory aliasing의 경우 또한 고려했기 때문이다. x와 y가 같은 주소를 가리키는 포인터였다면, 위의 함수는 x가 원래의 2배가 아닌 4배가 되고, 아래의 함수는 3배가 증가하게 된다. 

이러한 경우를 해결하기 위해, C99 이상에선 restrict라는 키워드를 제공하여, 컴파일러가 memory aliasing 등에 대한 고려 없이 최적화를 하도록 지시할 수 있다. 


# 성능의 측정 (CPE)
CPE(Cycles Per Element)는 루프 등에 의한 반복 연산의 performance를 측정 및 표현하는 데 적합하다. 프로세서는 Hz 단위로 표시되는 특정 주파수의 클럭에 의해 제어되는데, 가령 4 GHz의 프로세서라면 초당 40억의 사이클로 동작한다고 볼 수 있다. 이 사이클을 instruction, 또는 operation 하나에 대응시킬 수 있기 때문에, 우리는 성능을 측정할 때 (프로세서의 성능 등에 의존할) 절대적인 시간이 아닌 __연산 횟수__ 를 이용할 수 있다. 

사실 CPE라는 단어를 제외하면 거의 모두가 익숙해할 개념이므로 가볍게 넘어가고, 다음 시간엔 각종 최적화 기법에 대해 알아보려고 한다.
