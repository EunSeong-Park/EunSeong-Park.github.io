---
title:  "12 가상 메모리 (1)"
toc: true
tags: CS:APP
---

# Intro
프로세스들은 CPU와 메인 메모리 자원을 공유하는데, 그 과정에서 공간의 부족, 다른 영역으로의 침범, 성능 저하 등 많은 문제가 발생할 수 있다. 그래서 시스템은 가상 메모리(virtual memory)라는 메인 메모리의 abstraction을 제공하여, 각 프로세스가 private address space를 가질 수 있도록 한다. 이러한 가상 메모리 개념은 메모리 사용의 효율성, 관리의 단순화, 각 프로세스의 주소 공간 보호 등 많은 긍정적인 영향을 주었다.

이러한 가상 메모리의 효과도 있지만, 우리가 가상 메모리에 대한 이해가 필요한 이유가 따로 있다. 

1. 가상 메모리는 모든 level에 스며들어 있어, 컴퓨터의 많은 부분을 설계하는 데 중요한 역할을 수행하고 있다. 즉, 가상 메모리에 대한 이해를 통해 컴퓨터 시스템이 동작하는 방식과 과정을 더 잘 이해할 수 있게 된다.
2. 가상 메모리는 메모리에 대한 다양한 강력한 기능을 제공하고 있다. 우리는 가상 메모리를 공부함으로써 그러한 기능들을 실제 응용 프로그램 설계 시 적용할 수 있을 것이다.
3. 가상 메모리는 잘못 사용되면 미묘하면서도 치명적인 오류를 발생시킬 수도 있기 때문에, 가상 메모리와 그것을 관리하는 할당 패키지를 이해하여 에러를 피해야 한다.

이번엔 가상 메모리가 어떻게 작동하고, 시스템에 어떤 이점을 주는지 등에 알아볼 예정이다.


# PA/VA & Address Space 
메인 메모리는 M개의 연속된 바이트 셀의 배열로 이루어져 있고, 각 바이트는 각자의, 그리고 고유한 physical address(PA)를 가진다. 이 때, CPU는 PA를 이용한, 가장 단순한 방식의 메모리 접근이 가능한데, 이를 physical addressing이라고 한다.

![](/imgs/csapp/54.png)

하지만 오늘날의 컴퓨터는 virtual addressing이라는 새로운 주소지정 방식을 사용한다. CPU는 virtual addressing으로 virtual address(VA)를 생성하여 메인 메모리에 접근하며, 이것은 메모리에 보내지기 전에 그에 대응하는 PA로 변환된다. VA에서 PA로의 변환 과정은 CPU 칩 내 MMU(Memory Managememt Unit)가 메인 메모리에 저장된 참조 테이블(OS에 의해 관리된다)을 참조하며 이루어지는데, 그 과정을 주소 번역이라고 한다.

![](/imgs/csapp/55.png)

여기서 잠깐 주소 공간(address space)에 대한 개념을 짚고 넘어가자.

![](/imgs/csapp/56.png)


# Virtual Memory (VM)
맨 위에서도 언급했지만, 가상 메모리(virtual memory)는 메모리 관리의 효율성, 단순화, 그리고 안정성 등 다양한 측면에서 유용하다. 우리는 이제 이를 각각의 측면에서 알아보려고 한다.

## VM for Caching
앞서 언급했듯, 결국 VM은 디스크에 저장된 N개의 연속적 바이트 배열로 볼 수 있어, 각 바이트는 고유한 VA를 가져, 이는 배열의 index로도 사용될 수 있다. VM 시스템은 VM을 특정한 사이즈 블록 단위로 분할하여 관리하는데, 이를 가상 페이지(virtual page, VP)라고 한다. 이와 비슷하게, physical memory도 물리 페이지(physical page, PP)로 분할되어 관리한다.

가상 페이지는 다음과 같은 세 상태의 페이지로 구분할 수 있다. 아래 그림을 참고하자.

- Unallocated : 아직 할당되지 않은 페이지, 디스크 상에서 공간을 차지하지 않는다.
- Cached : 물리 메모리에 캐시되어 할당된 페이지
- Uncached : 물리 메모리에 캐시되지 않은 할당된 페이지

![](/imgs/csapp/57.png)

페이지 테이블(page table)은 DRAM에 상주하는 VP를 PP로 매핑하는 PTE(Page Table Entry)의 배열이다. 이해를 위해 단순화된 페이지 테이블의 구조를 확인해보자. 각 PTE는 한 개의 유효(valid) 비트, n-bit의 주소 필드로 구성되어있다고 가정한다. 유효 비트가 세팅되었다면, 주소 필드는 가상 페이지가 캐시되어 대응되는 DRAM PP의 시작을 나타낸다. 반면, 세팅되지 않았다면 uncached entry의 주소는 디스크 상 VP의 시작을 나타내며, unallocated된 entry는 null을 가리킨다.

![](/imgs/csapp/58.png)

VM 시스템은 페이지 테이블을 통해 VP를 관리하고, MMU 내의 주소 번역 하드웨어는 VA를 PA로 변환할 때마다 페이지 테이블을 읽는 등 각 파트가 긴밀히 협력함으로써 VP는 잘 캐시되고 관리될 수 있다.

### Page Hit
VM 내의 어떤 워드를 참조해야하는 경우를 생각해보자. MMU 내 주소 번역 하드웨어는 Page table에서 유효 비트 확인으로 해당 워드가 physical memory(DRAM)에 캐시되어있는지 그 여부를 확인할 수 있다. 캐시되어 있다면(DRAM cache hit) 해당 PTE의 PA를 이용해 요청받은 PA를 구성할 수 있다.

![](/imgs/csapp/59.png)

위 그림에서는 VP 2에 해당하는 워드를 읽으려 한다. 주소 번역 하드웨어는 PTE 2를 찾기 위해 인덱스로 VA를 사용하였고, 이를 메모리 내에서 읽는다. 유효 비트가 세팅되었으므로, 주소 번역 하드웨어는 VP 2가 메모리에 캐시되었음을 확인하고, PTE 2가 가리키는 PA를 통해 그 워드의 PA를 구성할 수 있다.

### Page Fault
요청 받은 VM 워드가 DRAM에 캐시되지 않았다면(DRAM cache miss) 이는 page fault를 발생시킨다. 즉, PTE의 유효 비트가 세팅되어있지 않음을 확인한 경우다. 이 때 발생한 fault(exception)를 처리하기 위해, 핸들러가 호출되는데, 핸들러는 희생자(victim)가 될 페이지를 골라 추방(evict)시킨다(즉, 캐시를 해제한다). 그리고 그 비게 된 physical memory 공간에 원래 요청했던 VP를 캐시한 다음 리턴한다. Fault이므로 핸들러는 fault를 유발한 인스트럭션을 재시작하고, 요청한 VP는 메모리에 캐시되어 있으므로 exception 없이 page hit가 일어난다.

![](/imgs/csapp/60.png)

![](/imgs/csapp/61.png)

이 때 우리는 미스가 발생하면 DRAM과 디스크 사이에서 일종의 swapping(victim과 requested 사이에서)이 일어남을 알 수 있다. 이렇게 swapping이 끝나 요청한 VP가 들어오기 까지 기다리는 방식을 demand paging이라 한다.

### Allocating Page
새로운 페이지를 할당할 때, (즉, unallocated->uncached) 디스크 상에 새로운 페이지를 위한 공간이 만들어지고, 그에 해당하는 PTE는 새로이 만들어지는 페이지를 가리키게 된다. 아래 그림은 VP 5를 할당하는 경우다.

![](/imgs/csapp/62.png)

### Locality
어떻게 본다면 가상 메모리는 miss로 인한 cost로 인해 굉장히 비효율적인 것처럼 보인다. 특히, miss를 (DRAM보다 10만 배는 더 느린) 디스크에서 처리해야하므로 더더욱 그렇게 보이는데, locality의 영향으로 가상메모리는 생각보다 효율적으로 잘 작동한다.

Working set(동작 집합)이라는 작은 페이지 집합이 존재하여, 프로그램은 주로 동작 집합 내의 페이지에 액세스하는 경향이 있도록 한다. 그리고 더 잘 만든 프로그램일수록 더 작은 동작 집합을 가져 더 좋은 temporal locality를 가질 것을 기대할 수 있다. 그러나 만약 동작 집합이 메인 메모리보다 크다면, 매번 miss에 의한 swapping을 반복하게 되는 thrashing이라는 상황을 일으킬 수 있다.

다음 파트로 넘어가기 전 간단히 정리해보자. 가상 메모리는 캐싱 도구로 사용됨으로써 제한된 DRAM의 용량을 더더욱 활용할 수 있다. 사용될 데이터만을 DRAM에 저장해 빠르게 접근하며, 나머지는 디스크 내의 가상 메모리에 저장하고, 가상 메모리 내의 데이터가 필요한 경우, 디스크와 DRAM 간의 swapping으로 이를 캐시해서 접근할 수 있다.

## VM for Memory Management
가장 중요한 포인트는 각각의 프로세스가 그들만의 virtual address space를 가진다는 점이다. 우리는 그럼으로써 메모리를 단순한 선형적 배열로 볼 수 있고, 다른 프로세스가 메모리 공간의 어느 부분을 쓰고있는지 걱정하지 않아도 된다. 메모리 관리 측면에서 VM의 유용함에 대해 하나하나 짚어보자.

### 링킹 및 로딩 단순화
프로세스마다 별도로 분리된 주소 공간은 링커가 코드 및 데이터 등에 위치에 대한 일괄적인 포맷을 가질 수 있도록 해준다. 예를 들어, 64-bit address space에서 read-only code segment는 반드시 0x400000에서 시작한다. 주소 공간이 분리되어있지 않다면, 매 프로세스마다 해당 segment의 주소를 다르게 해야할 것이다.

그리고 로딩 시 실행파일 및 공유 목적파일을 메모리에 로드하기 쉽게 해준다. 더 궁금하면 책을 보자.

### 공유 단순화
대부분의 경우, VP를 중첩되지 않는 PP로 매핑하는 페이지 테이블이 만들어지지만, 필요한 경우 여러 개의 VP가 하나의 PP에 매핑되도록 할 수 있다. OS kernel code, 표준 C 라이브러리 함수 등과 같이 모두가 공통적으로 사용하는 데이터의 경우 더더욱 그렇다.

![](/imgs/csapp/63.png)

### 메모리 할당 단순화
사용자 프로세스에서 `malloc` 등으로 인해 추가적인 메모리를 할당해야 하는 상황에서도 가상 메모리가 유용하게 쓰인다. OS는 연속적인 VP를 physical memory 위의 임의의 PP에 매핑시킬 수 있다. 그렇다면 OS는 physical memory에서 (할당해야하는) 연속적인 PP를 찾을 필요가 없게 된다.


## VM for Memory Protection
PTE는 권한을 설정하기 위한 permission bit가 존재하여, MMU는 해당 페이지로의 접근을 시도할 때마다 permission bit를 체크한다. 예를 들어 `SUP`가 세팅되었다면 그 페이지는 커널 모드일 때만 접근 가능하며, `READ`와 `WRITE`, `EXEC` 는 각각의 읽기/쓰기/실행 허용 여부를 설정한다. 

![](/imgs/csapp/64.png)


## Address Translation
주소 번역 파트는 간단하게 알아보고 넘어가자.

앞서 언급했듯, 주소 번역은 VAS(Virtual Address Space)에서 PAS(Physical Address Space)로의 매핑이다. 페이지의 캐시 여부에 따라 매핑되는 PP가 있을 수도, 없을 수도 있다. 매핑되는 PP가 없다면 유효하지 않는 주소거나 디스크에 저장된 경우일 것이다. 본격적으로 보기 전에 몇 가지 정리하고 가자.

Symbol | Description
---|---
N = 2^n | Virtual address space의 주소 수
M = 2^m | Physical address space의 주소 수
P = 2^p | Page size (in byte)
TLBI | TLB index
TLBT | TLB tag
VPO | Virtual page offset
VPN | Virtual page number
PPO | Physical page offset
PPN | Physical page number

아래 그림은 MMU가 매핑을 위해 페이지 테이블을 어떻게 사용하는지를 보여준다. 가볍게 훑어봐도 이해할 수 있을 정도니 천천히 보자.

![](/imgs/csapp/65.png)
 
이제, page hit와 page fault 두 경우로 나누어서 주소 번역의 과정을 알아보도록 하자.

### Address Translation - Page Hit

1. 프로세서가 가상 주소를 생성하고 이를 MMU에 전송한다,
2. MMU는 PTE 주소를 생성한 다음, 이를 캐시 / 메인 메모리에 요청한다.
3. 캐시 / 메인 메모리는 PTE를 MMU에 리턴한다.
4. MMU는 물리 주소를 구성하고, 이를 캐시 / 메인 메모리로 보낸다.
5. 캐시 / 메인 메모리는 요청한 워드를 프로세서로 보낸다.

### Address Translation - Page Fault
1. 1 ~ 3단계는 page hit의 경우와 동일하다.
2. PTE의 valid가 0이므로, MMU는 exception을 발생시킨다.
3. 핸들러는 제어를 넘겨받고 메모리 내에서 victim을 결정한 뒤 스와핑한다.
4. 핸들러는 PTE를 갱신하고 제어를 돌려주며 오류 인스트럭션으로 돌아간다.
5. 이후 같은 시도로 page hit.



