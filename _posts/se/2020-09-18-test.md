---
title:  "[Software Engineering 2] Testing"
tags: Software-Engineering
toc: true
---

# Intro
비단 오류뿐만 아니라 의도하지 않은 결과, 흐름, 혹은 예상보다 낮은 퍼포먼스 등과 같이, 프로그램이 의도하지 않은 방향으로 실행되는 경우는 아주 많다. 테스트는 이를 잡아내고 수정 및 보수하기 위함이며, 이를 위한 체계적인 방법들이 많다. 

여기선 테스트에 관한 몇 가지 기본적인 개념을 예시와 함께 알아보고, 적절한 테스트 스위트를 만들기 위한 방법을 살펴보자.


# Basic Concepts
## Fault / Error / Failure
Fault, error, failure, 이 세 단어는 비슷한 의미로 사용되지만, 몇 가지 분명한 차이점이 있다. 

Type | Description
---|---
Failure | 외부로 드러나는 incorrect behavior
Error | 프로그램의 incorrect intenal state 
Fault | SW의 정적인 결함

Fault는 error를 야기할 수도 있고, 그렇지 않을 수도 있다. 또한, error는 failure를 야기할 수도 있고, 그렇지 않을 수도 있다. 예를 들어, `{1, 2, 3, 4, 5}`로 저장되어야할 어떤 배열, `A`가 `{1, 2, 3, 4, 6}`으로 저장되었다고 치자. 그렇게 만든 코드를 fault라 부르며, 그로 인한 이 잘못된 상태를 error라 부른다. 만약 `A[4]`를 읽어 출력하려 한다면 이는 failure로 이어지지만, 다른 부분을 읽는다면 failure로 이어지지 않는다.

## Coverage
어떤 경우에 error가, fault가, 그리고 failure가 일어날까? 우리는 테스트를 통해 이를 확인하고 싶다. 하지만 이는 실제로 꽤 어려운 일이다. 예시로 아래 코드를 보자.

```c
if (x - 100 <= 0)
    if (y - 100 <= 0)
        if (x+y == 200)
            crash();
```
여기서 `crash()`는 언제 일어날까? 오직 `(100, 100)`인 경우뿐이다. 이 때 문제가 드러나는데, `int` 타입을 가정했을 때, $2^{31} * 2^{31}$의 케이스를 중에 단 하나만 fault를 발생시킨다. 

이런 경우 exhaustive한 테스트는 실질적으로 불가능하다. 너무 코스트가 크기 때문이다. 그렇다고 랜덤으로 인풋을 결정해 테스트한다고 해서 달라질까? 이 또한 0에 가까운 확률이다. 이런!

우리는 최대한 많은 경우를 고려해 테스트하고 싶지만, 그와 동시에 효율적인 테스트를 하고 싶다. 무조건 많은 수의 테스트가 왕도는 아닌 셈이다. 이제, 효과적이면서도 효율적인 테스트를 위해, 커버리지(Coverage)라는 개념을 도입해보자.

커버리지의 기본 아이디어는 이렇다. "프로그램의 많은 부분이 커버될 수록, 버그를 찾아낼 가능성이 더 높다!" 그런데, 여기서 "많은 부분"이란 정확히 무엇을 의미하는 걸까? 여러 측면에서 Coverage metrics를 정의할 수 있다.

### Line Coverage
라인 커버리지는 테스트 케이스들에 의해 실행된 소스 코드 라인의 비율이다. 가장 직관적이고 간단한 메트릭으로 볼 수 있다. 그런데,

```c
for (int i=0; i < n; i++>){sum += i; product *= i} printf("done.");
```

이걸 한 줄로 보는 게 정녕 맞을까?

### Statement Coverage
줄 대신, 이젠 구문(statement)을 기준으로 실행된 비율을 따져볼 수 있다. 라인 커버리지보다 조금 더 괜찮아보이지만, 모든 구문을 실행하는 게 반드시 완벽한 테스트가 됨을 보장할 수 있을까? 아래 예시를 보자.

```cpp
int x, y;
if (x < y) x += 10000;
if (x > y) y += 10000;
cout << x << y;
```

여기에 테스트 케이스, `{x, y} = {100, 1000}, {1000, 2000}`을 넣는다고 가정하자. 분명 모든 statement가 실행된다. 하지만 이 테스트 케이스 셋에선 첫 번째 `if`를 건너지 않는 flow가 없다. 뭔가 부족한 느낌이다.

### Branch Coverage
브랜치 커버리지는 테스트 케이스에 의해 분기가 실행되는 비율이다. 즉, control flow graph에서 edge(간선?)들을 얼마나 실행시키는지에 대한 지표다. 위의 예시 코드를 CFG(Control Flow Graph)로 표현해보자.

![](/imgs/se/se1.png)

(그림판 ㅈㅅ) 테스트 케이스가 커버하지 못하는 분기(edge)가 있음을 명확히 파악할 수 있다. 또, 이러한 점에서, 다음과 같은 사실을 알 수 있다.

> 테스트가 모든 분기를 커버한다면 모든 구문 또한 커버된다. 하지만 모든 구문을 커버한다고 모든 분기의 커버를 보장하지는 않는다.

CFG를 작성할 때, 불가능한 branch는 제외해야 함을 알아두자. 예를 들어,

```cpp
if (false) printf("false");
else printf("true");
```

### Condition/Decision Coverage
이번엔 테스트 케이스가 얼마나 많은 비중의 condition set을 실행했는지를 따져보자. 예를 들어보자.

```cpp
if (x > y || x - 1 > y) printf("1");
if (x + 1 > y) printf("2");
if (x + 2 > y) printf("3");
if (x + 3 > y) printf("4");
```

불가능한 경우는 없으므로, 총 $2^5 = 32$의 condition이 존재한다. 그런데 여기서 생각해볼 것이 있다. "프로그램을 작성하면 수 십, 수 백 개의 조건식이 들어갈텐데, 그렇다면 테스트 케이스가 너무 많이 필요한 거 아닌가?" 그래서 우리는 MC/DC(Modified Condition/Decision Coverage)를 도입한다.

`if (A && B && C)`를 생각해보자. 이는 다음과 같이 표현할 수 있다.

A | B | C | Decision
---|---|---|---
T | T | T | T
F | T | T | F
T | F | T | F
T | T | F | F
F | F | T | F
F | T | F | F
T | F | F | F
F | F | F | F

A를 기준으로 살펴보자. `{B, C} = {T, T}`면  A에 따라 decision이 결정된다. 마찬가지로, `{A, C} = {T, T}`일 때는 B에 의해, `{A, B} = {T, T}`일 땐 C에 의해 decision이 결정된다. 그렇다면 우리는, `{F, T, T}`, `{T, F, T}`, `{T, T, F}`, `{T, T, T}`, 총 네 종류의 테스트만을 수행하면 된다.

### Path Coverage
프로그램의 결과와 상태는 프로그램이 실행된 경로에 의존한다. 이젠 branch에서 더 나아가, 명령과 실행이 어떤 경로를 따라 이루어졌는지를 따져본다.

아래 예시를 살펴보자.

```cpp
...
if (x >= 0) printf("x is positive");
else printf("x is negative");
if (y >= 0) printf("y is positive");
else printf("y is negative");
...
```

이는 CFG로 나타내면 다음과 같고, 테스트 케이스 `{1, -1}, {-1, 1}`에 따른 flow는 각각 빨강 / 파랑으로 표시하였다. (발그림 ㅈㅅㅎ)

![](/imgs/se/se2.png)

이 테스트 케이스는 모든 분기를 커버하지만, 모든 경로를 커버하진 못한다는 사실을 알 수 있다. 이제 여기서 드는 의문이 조금 있을텐데,

- 그러면 그 exponential한 모든 경로를 다 생각해야 하나?
- 만약 루프가 나오면 어떡하나?

이런 점에서, 완전히 모든 경로를 커버하는 complete path coverage는 달성하기 불가능한 것처럼 보인다. 대신, 우리는 이를 조금 간단하게 만들 수는 있다. 바로 simple path coverage로!

Simple path coverage는 그래프에서 (처음 노드와 마지막 노드를 제외하고) 한 번을 초과하여 방문하는 노드가 없도록 path를 결정한다. 이에 더하여, 다른 경로의 subpath가 되지 않는, prime path만을 테스트한다면 더욱 효율적인 테스트가 가능할 것이다.

### Reflection
결국, 무조건 많이 테스트하는 게 왕도는 아니란 사실을 알았다. (costly하므로!) 적절한 커버리지 메트릭을 사용해, cost-efficiency하면서도 effective한 테스트를 해보자!


## White / Black Box Testing
Black box testing은 functional testing이라고도 부르며, 코드나 내부 구조, 작동 원리를 모르는 상태에서 테스트 케이스를 구성하고 실행하는 방법이다. 소프트웨어의 역할 및 목적 등과 같이 외부적으로 알려진 정보만을 한정적으로 가지고 수행한다. 그렇기에 우리는 기능적인 측면에서 소프트웨어를 바라보고 테스트하게 된다.

예를 들어, 다음과 같은 팩토리얼 함수를 만드는 경우를 생각해보자.

> Input, `n`에 대하여, $n < 0$이면 invalid input에 의한 에러 메세지를 출력하고, $0 \le n < 20$이면 $n!$에 대한 정확한 값을 출력한다. 또, $20 \le n < 200$이면 부동소수점 포맷을 이용해 어느 정도 가까운 근사치를 출력하며, 200 이상이라면 invalid input으로 여겨 에러 메세지를 띄운다.

이 경우, 입력을 크게 네 구간으로 분할하여 볼 수 있을 것이다. 이러한 과정과 그것의 분할을 equivalence class partition (ECP)라고 한다. 기능별로 구분되는 네 구간을 분할하여서, 같은 파티션에 속한 인풋은 비슷하게 동작할 것을 기대할 수 있다.

반면, white box testing은 소프트웨어의 내부 구조와 작동 방식 등을 테스트한다. 위에서 열심히 살펴본 커버리지는 화이트 박스와 더 연관있을 것이다. 왜냐? 내부 구조를 모르면 커버리지를 판단할 수 없기 때문이다.

## Types of Testing
조금 더 넓은 관점에서 다시 테스트를 바라보자. 테스트는 크게 네 종류로 나누어 볼 수 있다.

- Unit testing: 독립된 환경에서 하나의 모듈 혹은 함수를 테스트한다.
- Integration testing: 다수의 모듈이 결합된 시스템의 일부를 테스트한다.
- System testing: 전체 시스템을 테스트한다.
- Acceptance testing: 소프트웨어와 그것의 시스템이 원래의 목적과 요구 사항을 충족하는지 테스트한다.

마지막 3, 4번은 조금 혼동될 수 있는데, [여기](https://www.geeksforgeeks.org/difference-between-system-testing-and-acceptance-testing/)에 정리가 깔끔하게 되어있다. 시간 나면 읽어보자.

## Test Doubles
Unit test에서 생길 수 있는 문제점이 있다. 어떤 모듈은 독립적으로 작동할 수 있고, 그것에 대한 테스트가 그 모듈의 작동 여부를 잘 보여주지만, 어떤 모듈은 다른 모듈에 종속적이기도 하다. 만약 상호작용해야 하는 다른 모듈이 아직 준비되지 않았거나, 네트워크, DB 등과의 상호작용을 포함하여 매우 costly하다면? 

Test double은 그러한 상황에서, 실제 모듈 대신에 사용할 수 있도록 하는 단순화된 대체품이다. Test double은 그 종류가 다양하지만, 대표적인 몇 가지만 알아보도록 하자.

- **Dummy**는 동작이 대부분 구현되지 않고, 인스턴스로서의 역할만을 수행하는 테스트 더블이다. 동작이 대부분 구현되지 않으므로, 테스트에서 그것의 기능을 필요로하지 않을 때 유용하다.
- **Fake**는 복잡한 매커니즘/로직과 동작을 단순화하여 구현한 객체를 의미한다. 복잡한 알고리즘 혹은 케이스들을 간소화하거나, 외부와의 상호작용을 다른 것으로 대체하는 등(리스트나 해시 등으로 DB를 대체한다거나)으로 단순화한다.
- **Stub**은 dummy에 가짜 기능을 추가한 형태다. 로직과 실제 코드는 구현되지 않았지만, 외부에서는 그렇게 느끼게끔 가짜 결과를 제공한다. 즉, 인터페이스와 간단한 형태는 잡힌 셈이다. 
- **Mock**은 stub과 비슷하지만, 테스트를 위한 특정한 행동을 하도록 한다는 점에서 다르다. Stub이 특정 결과를 뱉도록 한다면, Mock은 특정 행동을 하도록 한다. 엄밀히 말하면 정확한 설명은 아니지만, 대충 그런 개념이다.

## Regression Testing
회귀(regression) 테스트는 이전에 발생한 문제에 대하여, 이를 반영하는 테스트 케이스를 추가하고, 유지/보수/수정 후 이를 적용하여 재발을 막는 방식이다. 이러한 방식의 테스트 스위트는 지속적으로 업데이트되며, 그래야만 한다. 그 특성 상 업데이트와 리포팅이 자동화될 수도 있다.


# Test Generation
지금까지 테스트에 대한 전반적인 개념을 알아보았다. 이로써 우린 테스트를 cost-efficient하고 effective하게 구성할 아이디어를 얻게 되었다. 이젠, 그러한 테스트를 만들어내는 (그것도 자동적으로!) 방법에 대해 알아보도록 하자.

## Test Randomization
어떤 모듈, 프로그램에 대해 우리는 적절한 randomization을 적용함으로써 다양한 케이스에서의 테스트를 수행해볼 수 있다. 그러나, 만약 `int` 범위의 인풋을 받는 어떤 기능이 있을 때, `int` 전체 범위에서 랜덤 인풋을 넣는 게 과연 바람직할까? 바람직할 수도 있고, 그렇지 않을 수도 있다. (어떤 모듈/기능/프로그램이냐에 따라 다를 것이다.) 아무튼, 우리는 randomization에서도 적절한 전략을 취해야 한다.

그 전에, randomization의 대상은 무엇일까? 일반적으론, 그리고 직관적으론 보통 input에 대한 randomization을 떠올린다. 하지만 비단 input뿐 아니라, scenario, 즉, 다수 테스트의 순서나 과정, 그리고 그것의 조합들을 randomize할 수도 있다!

Input이나 scenario나, blind한 randomization은 효율적이지 못하다. 왜냐? 같은 기능과 결과를 낳는 테스트가 중복될 수도 있고, 어떤 유용하지 않은 input/scenario와 그것의 조합들은 meaningless한 테스트가 될 수 있기 때문이다. 또는, 테스트 단위 자체가 의미 없는 것일 수도 있다. 예를 들어, 다음 코드를 보자.

```java
// 해당 테스트가 이미 있다고 가정하자.
public void test(){
    Stack<Integer> stack = new stack<>();
    stack.push(new Integer(10));
    stack.pop();
}

// 위 테스트와 같은 program state와 result에 도달하기 때문에 필요없다.
public void useless(){
    Stack<Integer> stack = new stack<>();
    stack.isEmpty();
    stack.push(new Integer(10));
    stack.pop();
}
```

```java
// 해당 테스트가 이미 있다고 가정하자.
public void test(){
    Stack<Integer> stack = new stack<>();
    stack.pop(); // throw exception
}

// Exception 이후의 코드에 도달하지 못한다 -> redundant!
public void useless(){
    Stack<Integer> stack = new stack<>();
    stack.pop();
    stack.push(new Integer(10));
    stack.pop();
}
```

이제 대충 어떻게 테스트를 구성해야 할지에 대한 아이디어를 얻었다. 그렇다면 그러한 테스트들을 어떻게 실제로 만들어내고 적용할까? 직접 수작업으로..?


## Randoop
Randoop은 RANDom tester for Object-Oriented Programs의 약자로, 단어 그대로 OOP(Java class)에 대한 유닛 테스트를 자동적으로 생성해주는 도구다. [여기](https://randoop.github.io/randoop/)서 자세한 설명을 볼 수 있다.

간단히 말하자면, Randoop은 feedback-directed random test generation을 통해 유닛 테스트를 생성한다. 간단하게 Randoop이 작동하는 알고리즘을 살펴보자.

1. Java 메서드 $m$, 타입 $T_i$에 대하여, operation $m(T_1, T_2, \cdots, T_k)$를 결정한다.
2. 그에 따른 적당한 term, $t_1, t_2, \cdots, t_k$를 고른다. (컴포넌트(혹은 term) 집합, $C$로부터!)
3. $t := m(t_1, t_2, \cdots, t_k)$이 legal한지, 그리고 redundant하지 않는지 확인한다. (만약 그렇다면 $t$는 폐기한다)
4. $t$가 에러를 발생시키는지 확인하고, 발생시킨다면 output으로, 그렇지 않다면 $C$에 $t$를 추가한다.

이러한 방식으로, vaild & efficient한 테스트를 만들어낼 수 있다.

## EvoSuite
EvoSuite 또한 테스트를 자동적으로 생성하기 위한 도구다. Randoop과 비슷하게 random test generation을 수행하지만, EvoSuite는 커버리지에 의해 guided된다는 점에서 조금 차이가 있다. 즉, 커버리지를 개선하기 위한 도구로 사용될 수 있다. 일단 [공식 사이트](https://www.evosuite.org/)를 참고하자. 하이고 영어 읽기 싫다...

EvoSuite는 커버리지 개선을 위해, ML과 유사한 최적화 알고리즘을 사용한다. (loss function이 그렇듯) Fitness function을 도입하여, (weight를 업데이트 하듯) test suite를 업데이트하면서 최적해를 찾는다. 가령 특정 테스트가 커버리지 증가에 기여하지 않는다면 discard하는 등의 행동을 취할 수 있다. 하지만 이건 너무 러프한 설명이고, 우선, test suite, $T$에 대한 fitness function을 다음과 같이 정의하자.

$\text{fitness}(T) = \vert M \vert - \vert M_T \vert + sum_{b_k \in B} d(b_k, T)$

Loss function이 그렇듯, fitness가 0일 때 가장 optimal하다. $\vert M \vert$은 메소드의 수, $\vert M_T \vert$는 $T$에 의해 실행된 메소드의 수, $B$는 SUT(software under testing)의 분기들의 집합이다. $d(b_k, T)$는 branch distance로, 다음과 같이 정의된다:

$$d(b, T) =
\begin{cases}
0 & \text{if the branch has been covered} \\
\nu(d_{min}(b, T) & \text{if branch is executed more than once} \\
1 & \text{otherwise}
\end{cases}
$$

먼저, branch distance는 다음과 같이 표현할 수 있다.

Target Branch | Branch Distance
---|---
`x == y` | `|x-y| == 0 ? 0 : k`
`x != y` | `|x-y| != 0 ? 0 : k`
`x > y` | `y-x < 0 ? 0 : y-x+k`
`x >= y` | `y-x <= 0 ? 0 : y-x+k`
`x < y` | `x-y < 0 ? 0 : x-y+k`
`x <= y` | `x-y <= 0 ? 0 : x-y+k`

그리고 $\nu$는 normalized된 (in $[0, 1]$) branch distance value다. ($\frac{x}{x+1}$에 의해 normalize된다.) 또한,  $\mu (d_{min}(b_k, T)$는 test suite, $T$의 모든 test case에 대해 계산되며, $d(b, T) \ge 0$이다. 각 branch들에 대해 minimal distance를 가지는 test case가 suite 내에 있으면 더 괜찮은 suite가 되는 셈이다.

이제 최적해를 fitness function을 이용해 잘 정의하였으므로, 이를 통해 optimal test suite를 찾을 방법이 필요하다. (ML이 그렇듯이) 많은 optimal solution을 위한 알고리즘이 있지만, 우리는 evolutionary algorithm(EA)를 사용할 것이다. 왜냐? Hill climbing과 같은 basic한 방법은 local optima에서 막히는(stuck) 고질적인 문제가 있기 때문이다. EA에 관한 디테일은 [여기](https://en.wikipedia.org/wiki/Evolutionary_algorithm)를 참고하자.
