---
title: "[Time Series Analysis 1] Trends"
tags: Time-Series-Analysis Management-Engineering Data-Science
toc: true
---

# Intro 
**트렌드(trend)**가 굉장히 복잡한 함수로 정의된다면, 혹은 임의의 함수 그것의 형태를 잡는 일은 불가능에 가까울 것이다. 만약 정상성을 지닌 시계열이라면? 트렌드는 분명 상수함수일 것이다. 두 극단적인 상황 대신, 우리는 **시간에 따라 변하지만, 적당히 간단한 형태를 지닌 트렌드**를 가정한다. 물론, 어느 형태를 잡든, 그렇게 모델을 가정한 것에 대한 적절한 근거가 있어야 한다.

우리는 시계열 데이터를 trend, seasonality, noise 등으로 나누어, 각각을 설명하기 위한 적절한 함수로 표현하는 게 목표다. 이번엔 트렌드를 중점적으로 알아보자.

# Types of Trends
어떤 주어진 데이터에 대하여, 트렌드를 **결정론적(deterministic)** 모델이나 **확률론적(stochastic)** 모델로 볼 수 있다. 둘의 차이는 결과가 오로지 초기 상태와 parameter에만 의존하는지, 아니면 결과에 어느 정도의 무작위성(randomness)이 수반되는지에 있다.

Random-walk process와 같은 확률론적 트렌드는 보통 파악하는 데 어려움이 있는데, 이는 용어 그대로 무작위성에 의존하기 때문이다. 프로세스의 시뮬레이션마다 결과가 조금씩, 또는 굉장히 크게 달라질 수 있다.

반면, 항상 동일한 트렌드 모델을 적용시킬 수 있는 것처럼 보이는 데이터도 있다. 트렌드가 결정론적인 경우다. 다음과 같이 표현해보자.

$$ Y_t = \mu_t + X_t $$ 

이제 우리는 $\mu_t$에 대한 적절한 함수를 찾고 싶다. 가령 선형적인 함수를 가정하라면 $mu_t = \beta_0 + \beta_1 t$일테고, 쿼드러틱하다면 $\mu_t = \beta_0 + \beta_1 t + \beta_2 t^2$일 것이다. 그런데 각각의 계수는 어떻게 구하면 좋을까? 


# Regression
**회귀(regression)**로 결정론적 트렌드에서 parameter를 추정(estimate)할 수 있다. Trend의 형태를 미리 가정하고, 그에 대한 parameter를 찾는 방식이다.

## Regression Method for Trends
### Linear / Quadratic Trends
우선, 선형(linear) 트렌드는 $\mu_t = \beta_0 + \beta_1 t$와 같이 표현할 수 있고, $\beta_0$은 intercept, $\beta_1$은 slope다. 이 경우, least square method를 통해, error를 minimize하는 방향으로 $\beta_0, \beta_1$을 추정할 수 있을 것이다. 여기서 error는 다음과 같이 나타낼 수 있다.

$$ Q(\beta_0, \beta_1) = \sum_{t=1}^{n} (Y_t - (\beta_0 + \beta_1t))^2 $$

비슷한 방식으로, quadratic trend도 parameter들을 추정할 수 있다.

$$ Q(\beta_0, \beta_1, \beta_2) = \sum_{t=1}^{n} (Y_t - (\beta_0 + \beta_1t + \beta_2t^2))^2 $$

### Cyclical / Seasonal Trends
연간 기온과 같은 seasonal data를 생각해보자. 우리는 season 내 각각에 대한 parameter가 필요하다. 예를 들어, 연간 기온에서는 Jan, Feb, ..., Dec에 대한 12개의 parameter가 필요하다. 그리고 그들에 대한 각각의 seasonal mean을 구하는 것으로 추정할 수 있다.

![](/imgs/mge/tsa3.png)

#### Cosine Trends
위에서, 우리는 seasonal trend를 찾기 위해, 이산적인 수($12$)의 independent parameter를 가정했다. 하지만 이러한 방식은 경우에 따라 불가능하거나, 비효율적이거나, 효과적이지 않을 수 있다. 가령, 우리는 처음에 잘 모르는 시계열 데이터에 대해 parameter의 수를 어떻게 결정하고 가정할 수 있을까? 우리는 seasonal trend를 코사인 커브를 통해 꽤 괜찮은 방식으로 추정할 수 있다.

$$\mu_t = \beta \text{cos}(2\pi f t + \Phi)$$

연속적인 형태를 생각하면서도, 추정할 parameter가 많지 않다는 점은 꽤 매력적이다. $\beta$는 amplitude, $f$는 frequency, $\Phi$는 phase다. 가령 위의 예시를 사용한다면, f는 $\frac{1}{12}$일 것이다.

아무튼, 우리는 여기서 각각의 parameter를 구해야 한다. 그 전에, reparametrization으로 식의 형태를 바꾸어보자.

$$ \mu_t = \beta_1 \text{cos}(2\pi ft) + \beta_2 \text{sin}(2\pi ft)$$, where $\beta^2 = {\beta_1}^{2} + {\beta_2}^{2} $, $\Phi = \text{arctan}(- \frac{\beta_2}{\beta_1})$

이에 더하여, intercept를 추가하면, 최종적으로 다음과 같은 간단한 c osine trend model을 세울 수 있다.

$$ \mu_t = \beta_0 + \beta_1 \text{cos}(2\pi ft) + \beta_2 \text{sin}(2\pi ft)$$


## Residual Analysis

$$ \hat{X_t} = Y_t - \hat{\mu_t} $$

**잔차(residual)**는 샘플로부터 얻은 추정치와 실제 관측값 사이의 차이다. (모집단으로부터 얻는 추정치와 비교하는 오차(error)와 조금 다르다) 즉, regression으로 어떤 식을 얻었을 때, 그것이 실제와 얼마나 차이가 나느냐?로 볼 수 있다.

Residual은 시계열 데이터에서 관측되지 않은 stochastic component를 추정할 때도 유용하다. 가령 {$X_t$}가 화이트 노이즈라면, residual은 zero-mean with standard deviation, $s$와 같은 양상을 보일 것이다. 

이러한 맥락에서, residual analysis는 regression model의 테스트의 도구로 사용할 수 있다. 잔차가 비정상적인 분포나 형태를 보인다면, 회귀에 사용한 가정/모델이 잘못되었거나, 어떤 이상치(outlier)가 있음을 추론할 수 있다.

이제부터, 잔차를 이용해 회귀모델이 적합한지를 판단해볼 것이다. 우선, 시계열의 회귀 분석은 **정규성(normality), 등분산성(homoscadicity), 독립성(independence)**을 가정으로 함을 기억하자.

### Terms
가령 잔차가 비교적 고른 분포를 가지고 있는데, zero-mean이 아니다? 그렇다면 회귀 모델이 추가로 상수항을 포함하고 있을 가능성이 높다. 예를 들면,

![](/imgs/mge/tsa4.png)

위 그래프는 $1500$개의 데이터에 대한 잔차 산점도다. 대충 normal해보이지만, $5$ 정도의 mean을 가지고 있는데, 이상적인 상황은 저걸 그대로 옮겨(그리고 모델을 $5$만큼 평행이동하여) zero-mean인 상황일 것이다.

이런 건 어떨까?

![](/imgs/mge/tsa5.png)

이 경우, 이차항이나 비슷한 무언가를 모델에 추가해주면 될 것 같다.

### Homoscadicity
등분산성(homoscadicity)은 잔차들이 일관적인 분산을 가지고 있는지에 대한 척도다. 점점 잔차들이 퍼지거나 좁아지면 등분산에 대한 가정은 무너지는 셈이다.

![](/imgs/mge/tsa6.png)

위 그래프는 zero-mean이지만, 등분산성은 없는 것 같다. 만약 모델이 등분산성을 가정했다면, 그 가정을 수정해야 한다.

### Independence
독립성 여부 판단은 방법이 조금 모호한데, 가장 간단한 방법으로 잔차의 분포나 autocorrelation을 확인하는 방법이 있다. 시각적으로 대놓고 종속적인 애들이 있을 수 있고, 유의미한 자기상관이 나오는 경우도 있다. 하지만 자기상관의 특성이 그렇듯, 이게 독립성을 완전히 설명해주진 못한다. (종속성은 잘 설명해줄지 몰라도)

아무튼 이를 위해, sample autocorrelation function을 사용할 수 있다. 정상성과 common mean, common variance를 가정하고, 다음과 같은 함수를 사용할 수 있다.

$\gamma_k = \frac{\sum_{t=k+1}^n (Y_t -\bar Y)(Y_{t-k} - \bar Y)}{\sum_{t=1}^n (Y_t - \bar{Y})^2}$

### Normality
사실 데이터가 충분히 크고 아웃라이어가 없으면 정규성 검정엔 크게 중점을 두지 않는다. 산점도를 보고 (mean으로 갈수록 그 밀도가 커지는지 등으로) 판단할 수도 있고 [Q-Q plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot)을 통해 확인할 수도 있다.

더 정확히 판단하려면, [Shapiro-Wilk test](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test)를 사용해보자. 위키로 너무 우려먹는 거 아닌가? 하핫

# 마치며
다음엔 정상성을 가정한 시계열 모델들에 대해 알아보자!