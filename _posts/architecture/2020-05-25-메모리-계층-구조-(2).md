---
title: "메모리 계층 구조 - 가상 메모리"
tags: Computer-Architecture
toc: true
---

# Intro
가상 메모리(virtual memory)는 메모리 계층 구조를 활용한 가장 대표적이면서도 중요한 예시다.

가상 메모리의 아이디어는 "메인 메모리를 디스크의 캐시로 쓴다"에서 시작된다. 그럼으로써 우리는 다음과 같은 장점을 얻는다.

- 제한된 크기의 메인 메모리의 제약을 완화한다.
- 메모리 영역을 효과적으로 공유하면서도 적절한 보호 매커니즘을 제공한다.

가상 메모리가 적용된 컴퓨터에서, 프로그램들은 각자의 사적 가상 주소 공간(private virtual address space)를 가지고, 가상 주소(virtual address)를 통해 메인 메모리에 접근한다. 가상 주소는 CPU와 OS의 협업에 의해 물리 주소(physical address)로 번역(translate)되어 실제 메모리 주소 공간에 매핑된다.

우리는 가상 메모리의 구조, 동작 방식을 알고, 가상 메모리에서 발생할 수 있는 여러 성능 문제를 해결하는 방법을 살펴보며, 효과적/효율적인 가상 메모리를 구현하는 방법을 알아볼 것이다.


# Address Translation
## Terminologies
VM(Virtual Memory)은 캐시의 형태를 띠고 있지만, 가상 메모리에서 사용하는 별도의 용어들이 몇 있다.

- Page: VM의 block을 의미한다.
- Page fault: VM translation에서의 miss를 의미한다.

## Page Table
페이지 테이블(page table)은 프로세스 각각이 메모리 내에서 가지는, 가상 주소(VA)에서 물리 주소(PA)로의 매핑을 수행하기 위한 테이블이다. 페이지 테이블에서 각각의 엔트리(PTE)는 주어진 VA에 대응되는 PA를 가리킨다. 

페이지 테이블의 동작 방식을 알기 위해, VA와 PA의 구조, 그리고 번역 방식을 간단히 알아보도록 하자.

![](/imgs/ca/ca9.png)

VA에서, VPN에 해당하는 비트로 PTE를 결정한다. 결정된 PTE에서, `Valid` 비트를 확인하여 유효한 주소 매핑이 존재하는지 확인하고, 유효하다면 PA로의 매핑을, 유효하지 않다면 페이지 폴트(page fault)를 발생시킨다.

이 때, 일반적인 캐시와 달리, PTE는 태그 비트를 포함하지 않는다. 왜냐? 페이지 테이블은 모든 가능한 VPN에 대한 매핑을 가지고 있기 때문이다. 유효한지의 여부와 상관없이 말이다. 그래서 VA에서 VPN이 $n$비트로 구성되어 있다면, 각 페이지 테이블은 $2^n$개의 PTE를 포함할 것이다.

아무튼 디스크에 있을 일부 블록들까지 고려하면, VM 시스템은 다음과 같은 구조를 가지게 된다.

![](/imgs/ca/ca10.png)

## Page Fault
참조한 PTE가 유효하지 않다면(invalid), 즉, 데이터가 메인 메모리에 없다면, 커널은 트랩(trap)을 걸어 페이지 폴트(page fault)를 발생시킨다.

페이지 폴트에 대한 처리(handling)는 일반적인 캐시와 비슷하게 작동하는데, 디스크의 스왑 스페이스(swap space)에 있는, 우리가 찾던 데이터를 메인 메모리에 가져온 뒤, PTE를 갱신한다음 이후 PTE 참조를 재시도한다.

__페이지 폴트는 굉장히 큰 비용을 발생시킨다.__ 그래서 조금이라도 실패율(miss rate)을 줄이기 위한 방향으로 VM이 설계된다. 

### Replacement Policies
페이지 폴트로 인해 디스크에 있는 데이터를 메모리로 가져오려면, 그런데 새 블록이 들어갈 메모리 공간이 없다면 기존의 PP을 빼내고 그 자리에 새 블록을 넣어야 한다. 교체할 블록을 결정하는 여러가지 방법이 있다.

- Random: 무작위로 쫓아낸다.
- LRU: Least-Recently Used. 사용한 지 가장 오래된 PP를 쫓아낸다.
- LFU: Least-Frequently Used. 가장 낮은 빈도로 사용된 PP를 쫓아낸다.

주로 LRU 방식이 사용되니, 이를 중점적으로 알아보자.

LRU는 각 PTE에 레퍼런스 비트(reference bit)를 추가함으로써 구현된다. 해당 페이지에 참조한 경우 비트를 1로 설정하며, 이들은 주기적으로 OS에 의해 0으로 초기화된다. 

교체 시점에서 레퍼런스 비트가 0이었다면, 이는 최근에 사용되지 않았음을 의미하므로 그 페이지를 쫓아낼 수 있다. 지역성의 원리에 의하여, 이러한 방식은 페이지 폴트의 가능성을 줄여줄 것이다.

### Writing Policy
이전 포스트에서 이미 알아보았지만, 쓰기 방식은 크게 write-through와 write-back으로 나뉜다. 

VM에서는 write-back 방식을 사용한다. 왜냐? 디스크로의 접근 및 쓰기는 엄청난 비용을 발생시키기 때문에, 블록이 교체될 때 단 한 번 쓰기를 수행하는 write-back 방식이 적절하기 때문이다. 우리는 교체 시 페이지에 쓰기가 발생했음을 알리기 위해 더티 비트(dirty bit)를 PTE에 추가한다.


# Translation-Lookaside Buffer
앞서, 우리는 주소 변환에 대한 과정을 간략히 알아보았다. 저 간단한 형태엔 하나 비효율적인 요소가 있다. 페이지 테이블은 메인 메모리에 저장되는데, 주소 변환을 위해 페이지 테이블을 참조하고(1), 참조한 PTE에 매핑되는 PP에 접근하므로(2), 총 두 번의 메모리 접근을 필요로 한다. 물론 디스크 접근에 비해선 별 거 아니지만, 메모리 접근도 상당한 비용을 낳으므로 이는 분명한 낭비다.

우리는 이를 해결하기 위해 페이지 테이블에 대한 캐시를 CPU에 도입할 수 있다. 이는 TLB(Translation-Lookaside Buffer)라고 불린다. 프로그램이 좋은 지역성을 가지는만큼 페이지 테이블로의 참조 또한 좋은 지역성을 가질 것이다. 그러한 프로그램에서 TLB는 좋은 성능 향상을 가져다 줄 것이다.

앞으로의 VM에 대한 논의는 TLB가 있다고 가정하고 이어간다.

## Translation by TLB

![](/imgs/ca/ca11.png)

주어진 VA에서 VPN을 뽑아내어, (일반적인 캐시처럼) TLB를 먼저 참조한다. TLB의 각 엔트리는 VPN에 대응하는 PP의 주소를 제공하거나, 페이지가 디스크 상에 존재함(페이지 폴트)을 알린다.

이 때, TLB는 페이지 테이블과 달리 태그 필드를 포함해야 한다. 일반적인 캐시가 그렇듯이 말이다.

## Miss Handling
TLB 참조시 캐시 미스가 발생하면(TLB 미스) 이에 대한 적절한 처리를 해야 한다. TLB 미스가 발생하는 덴 크게 두 케이스가 있다.

- 페이지가 메모리에 있지만, TLB에 캐시되지 않았다.
- 페이지가 메모리에도 존재하지 않는다. (페이지 폴트)

### TLB Miss Handling
우선 TLB 미스 발생 시, 예외(exception)를 발생시킨 다음, 메모리에 해당 페이지가 있는지를 확인하여 페이지 폴트 여부를 검사한다. 페이지 폴트가 아니라면, 단순히 메모리로부터 PTE를 캐시하여 같은 참조를 재시도하면 된다.

### Page Fault Handling
페이지 폴트가 발생하면 마음이 좀 아파진다. 페이지 폴트 발생 시, 폴트를 발생시킨 VA를 통해 PTE를 먼저 찾는다. PTE를 통해 디스크 내 페이지의 위치를 찾고, 메모리 내 다른 페이지와 교체한 뒤, 페이지 테이블을 갱신한다. 처리가 끝나면 폴트를 발생시킨 명령어로 돌아가 재시작한다.

## TLB and Cache Interaction
이제 우리가 지금까지 쌓아 올린 구조에 캐시를 도입한다. 메모리에 적재된 페이지를 더 빨리 접근할 수 있게 된다, 야호! 그런데 한 가지 중요한 문제가 남았다. "캐시 블록은 VA로 결정하는가, PA로 결정하는가?"

### Physically Addressed Cache
물리 주소 캐시는 TLB를 통해 PA로 변환한 다음, 이를 캐시 참조에 사용하는 방식의 캐시 구조다. 이러한 구조는 캐시의 히트 타임에 주소 변환에 필요한 시간을 더하게 된다. 물론 이는 파이프라이닝을 통해 개선될 수 있다.

_Intrinsity FastMATH_ 라는 임베디드 MIPS 프로세서는 물리 주소 캐시 방식을 선택했다. TLB를 통해 VA를 PA로 번역하고, 이를 다시 캐시 참조에 사용하는 걸 확인할 수 있다.

![](/imgs/ca/ca12.png)

### Virtually Addressed Cache
가상 주소 캐시는 VA를 바로 캐시 참조에 이용하는 경우다. 캐시는 VA에 의해 참조되므로, 캐시 히트 시엔 TLB를 거칠 필요가 없어 히트 타임을 줄여준다. 물론, 캐시 미스가 발생하면 TLB를 통해 주소 변환을 거친 뒤 메모리로부터 캐싱을 해야한다.

가상 주소 캐시는 여러 프로그램들의 메모리 공유 시 aliasing이 발생할 수 있다. 즉, 서로 다른 VA가 같은 PA에 매핑될 때, 캐시 내에서 그러한 블록들에 대해 모호함이 생긴다. 이러한 상황은 캐시 혹은 TLB의 정교한 설계나, 소프트웨어 차원에서의 조치를 필요로 한다.

이를 해결하기 위해, VA에 의해 인덱스되지만, 태그는 PA의 것을 따르는 방식도 있다. 이는 실제로 가상 주소 캐시보다 괜찮은 성능을 보이며, aliasing도 발생하지 않는다.

## Translation Cases
여기까지 왔으면, 우리는 TLB, 캐시, 페이지 테이블, 세 군데에서 히트 혹은 미스를 치게 된다. 가능한 경우에 대해 모두 알아보자.

TLB | Page Table | Cache | Description
---|---|---|---
Hit | Hit | Hit | 행복한 상황이다. 야호!$^+$
Hit | Hit | Miss | TLB 히트 후 캐시 미스 발생. 캐시 미스만을 처리하고 재시도한다.$^+$
Miss | Hit | Hit | TLB 미스, TLB로 PTE를 가져와 재시도하게 되고, 이후 성공한다.
Miss | Hit | Miss | TLB 미스, TLB로 PTE를 가져와 재시도하게 되고, 이후 캐시 미스가 발생하여 이를 처리하게 된다.
Miss | Miss | Miss | TLB 미스 이후 페이지 폴트. 페이지 폴트 처리 후, 재시도에서 캐시 미스가 발생한다. 
Hit | Miss | Miss | 페이지가 메모리에 없다면 TLB 히트가 불가능하다. 즉, 불가능한 케이스.
Hit | Miss | Miss | 페이지가 메모리에 없다면 TLB 히트가 불가능하다. 즉, 불가능한 케이스.
Miss | Miss | Hit | 페이지가 메모리에 없다면 캐시 히트가 불가능하다. 즉, 불가능한 케이스.

$^+$ TLB 히트 시 페이지 테이블을 굳이 체크하지 않는다. TLB 위에 있다는 것 자체가 이미 페이지가 메모리에 올라와있음을 나타내기 때문이다. 즉, 가능한 상황이지만 이러한 상황이 탐지되진 않는다.

# Other Issues
## Memory Protection
메모리 영역은 쉽게 공유될 수 있으면서도, 동시에 잘 보호되어야 한다. 메모리 보호는 PTE의 접근 권한 비트를 추가함으로써 이루어진다. 이러한 과정은 하드웨어와 소프트웨어가 협업해야 한다.

접근 권한 비트는 PTE에 할당되기 때문에, 같은 PP를 공유하더라도, 프로세스에 따라 그 권한을 다르게 할 수 있다. 예를 들어, 어떤 데이터에 대해 writer 프로세스와 reader 프로세스가 나누어져 있다면, 후자에게는 쓰기 권한을 주지 않을 수 있다.

또, 페이지 테이블이 포함하는 매핑은 커널 모드에서만 수정 가능하다. 페이지 테이블 조작에 의한 유효하지 않은 메모리 접근을 막기 위함이다.

그 외에도 많은 측면에서의 보호 기법이 존재한다.

## VM as a Cache
캐시의 측면에서, VM의 설계에 대해 생각해봐야 할 사항들이 있다. 몇 가지는 이미 알아보았지만, 다시 한 번 살펴보자.

### Block Placement
우리는 블록(여기서는 페이지) 할당 및 검색 정책을 결정하기 위해, 그것의 연관도(associativity)를 정한다. 디테일은 이전 포스팅에서 설명했으니 생략한다.

높은 연관도는 캐시 미스 비율을 낮추지만, 접근 시간, 비용, 그리고 구조의 복잡도를 증가시킨다. 하지만 그럼에도 VM은 항상 완전 연관(fully associative) 방식을 사용한다. 왜냐?

- 캐시 미스(페이지 폴트)에 따른 패널티가 굉장히 크다.
- 테이블은 모든 가능한 매핑을 포함하고 있어, 추가적인 HW나 검색 없이 쉽게 인덱스할 수 있다.

### Replacement Policy
앞서 블록 교체 정책들에 대해 알아보았다. 각각의 장단점이 있지만, VM에서는 항상 하드웨어 서포트를 받아 LRU approximation을 사용한다. 미스 비율을 조금이라도 줄이기 위한 시도다.

왜 미스 비율을 줄이기 위해 진짜 LRU가 아닌 LRU 근사를 사용하나? 싶은데, 아무래도 높은 연관 정도에서는 LRU의 구현이 어렵기 때문이 아닐까 싶다. 책에서는 4-way에서도 종종 LRU 근사 방식을 이용해야 할 정도라고 하는데, VM은 완전히 연관된 캐시 구조를 채택했으니...

# Exercises
## Virtual Memory
4 KiB 페이지와 4개의 엔트리를 가지는 fully-associative, LRU 교체 정책을 가지는 TLB를 가정하자. 페이지 테이블과 TLB의 초기 상태는 아래와 같고, 디스크에서 새로 페이지를 읽어 올 때, 그 번호는 가장 큰 페이지의 다음 번호다.

Valid | Tag | PPN | Used
---|---|---|---
1 | 11 | 12 | 3rd recently used
1 | 7 | 4 | Most
1 | 3 | 6 | 2nd recently used
0 | 4 | 9 | Least

VPN |Valid | PPN
---|---|---
0|1 | 5
1|0 | Disk
2|0 | Disk
3|1 | 6
4|1 | 9
5|1 | 11
6|0 | Disk
7|1 | 4
8|0 | Disk
9|0 | Disk
10|1 | 3
11|1 | 12

이러한 조건에서, 다음과 같은 가상 주소 스트림의 접근을 수행한다.

4669, 2227, 13916, 34587, 48870, 12608

> 각 참조에 대한 TLB hit / Page hit / Page fault 여부와 시스템의 최종 상태를 보이자.

페이지 크기가 $2^12 \text{bit}=4 \text{KiB}$이므로, 가상 주소의 하위 12비트는 페이지 오프셋, 나머지 상위 20비트는 VPN이 된다. 각 가상 주소에 대한 VPN은 다음과 같다.

VA: Decimal | VA: Binary | VPN
---|---|---
4669 | 0000 0000 0000 0000 0001 0010 0011 1101 | 1
2227 | 0000 0000 0000 0000 0000 1000 1011 0011 | 0
13916 | 0000 0000 0000 0000 0011 0110 0101 1100 | 3
34587 | 0000 0000 0000 0000 1000 0111 0001 1011 | 8
48870 | 0000 0000 0000 0000 1011 1110 1110 0110 | 11
12608 | 0000 0000 0000 0000 0011 0001 0100 0000 | 3

이제 주어진 가상 주소로의 접근을 하나하나 살펴보자.

VA | Result
---|---
4669 | TLB 미스 이후 페이지 폴트. 페이지 테이블에서 VPN 1은 PPN 13을 가리킨다. 이후 TLB 네 번째 엔트리를 교체한다. 
2227 | TLB 미스 이후 페이지 히트. TLB 첫 번째 엔트리를 교체한다.
13916 | TLB 히트.
34587 | TLB 미스 이후 페이지 폴트. 페이지 테이블에서 VPN 8은 PPN 14를 가리킨다. 이후 TLB 두 번째 엔트리를 교체한다.
48870 | TLB 미스 이후 페이지 히트. TLB 네 번째 엔트리를 교체한다.
12608 | TLB 히트.

TLB는 다음과 같은 상태가 된다.

Valid | Tag | PPN 
---|---|---
1 | 0 | 5 
1 | 8 | 14
1 | 3 | 6
1 | 11 | 12 

페이지 테이블은 다음과 같은 상태가 된다.

VPN |Valid | PPN
---|---|---
0|1 | 5
1|1 | 13
2|0 | Disk
3|1 | 6
4|1 | 9
5|1 | 11
6|0 | Disk
7|1 | 4
8|0 | Disk
9|1 | 3
10|1 | 3
11|1 | 12

> 페이지 크기를 16 KiB로 설정하고 위 과정을 다시 해보자.

이제 상위 18비트가 VPN을 결정한다. 즉, 가상 주소에 따른 VPN은 다음과 같다.

VA: Decimal | VA: Binary | VPN
---|---|---
4669 | 0000 0000 0000 0000 0001 0010 0011 1101 | 0
2227 | 0000 0000 0000 0000 0000 1000 1011 0011 | 0
13916 | 0000 0000 0000 0000 0011 0110 0101 1100 | 0
34587 | 0000 0000 0000 0000 1000 0111 0001 1011 | 2
48870 | 0000 0000 0000 0000 1011 1110 1110 0110 | 2
12608 | 0000 0000 0000 0000 0011 0001 0100 0000 | 0

VA | Result
---|---
4669 | TLB 미스 이후 페이지 히트. TLB 네 번째 엔트리를 교체한다.
2227 | TLB 히트.
13916 | TLB 히트.
34587 | TLB 미스 이후 페이지 폴트. 페이지 테이블에서 VPN 2는 PPN 13을 가리킨다.
48870 | TLB 히트.
12608 | TLB 히트.

Valid | Tag | PPN 
---|---|---
1 | 2 | 13 
1 | 7 | 4
1 | 3 | 6
1 | 0 | 5 

VPN |Valid | PPN
---|---|---
0|1 | 5
1|2 | 13
2|0 | Disk
3|1 | 6
4|1 | 9
5|1 | 11
6|0 | Disk
7|1 | 4
8|0 | Disk
9|0 | Disk
10|1 | 3
11|1 | 12


# 마치며
VM만 몇 바퀴를 돌았더니, 이해가 쏙쏙 되는 것 같다. CS에서 배우는 VM과 OS에서 배우는 VM, 그리고 Computer Architecture에서 배우는 VM은 다 느낌이 다르다. 여러 관점에서 하나의 개념을 보는 즐거움이 있다.