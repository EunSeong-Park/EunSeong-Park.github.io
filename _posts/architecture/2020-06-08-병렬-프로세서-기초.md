---
title: "병렬 프로세서 기초"
tags: Computer-Architecture
toc: true
---

# Intro
컴퓨터, 프로세서를 여러 개 연결하는 만큼 바로 성능이 좋아진다면 그야말로 행복한 세상이겠지만, 현실은 조금 더 복잡한 문제를 안고 있다. 우리는 "몇 개의 프로세서를 사용하든 프로그램은 잘 동작할 수 있는가?", "프로세서의 추가가 어느 정도의 성능을 가져다 주는가?" 와 같은 질문에 대한 대답을 생각해봐야 한다.


# Parallel Programming
## Difficulties
멀티 프로세서에 의한 병렬적 수행과 그것으로 인한 이득을 위해선, __애플리케이션이 반드시 concurrent해야 한다.__ 즉, 소프트웨어 개발 차원에서도 병렬 처리에 대한 고려가 이루어져야 한다. 주어진 작업을 균등하게 분배할 수 있는지, 분할된 작업 간의 통신을 위한 오버헤드가 얼마나 발생하는지, 작업을 합치고 동기화하는 데 얼마나 많은 비용이 발생하는지 등이 전부 고려되어야 한다.

예전에 암달의 법칙(Amdahl's Law)에 대해 잠깐 알아본 적이 있다. 성능 개선에 대한 구조적 한계를 설명하는 이 법칙은, 병럴 처리에도 예외 없이 적용된다.

$T_{\text{new}} = \frac{T_\text{parallelizable}}{\text{parallel}} + T_{\text{sequential}}$

병렬화 가능한 부분이 많을 수록, (병렬화가 잘 이루어졌다는 가정 하에) 병렬화에 의한 성능 향상 수준이 더 나아진다.

### Example
> $100$개의 프로세서로 90배의 속도 향상을 위해선 전체 프로그램에서 병렬화 가능한 부분이 어느 정도의 비율을 차지해야 할까?

암달의 법칙을 다음과 같이 표현할 수 있다.

$\text{Speed up} = {1 \over (1-F_{\text{parallelizable}}) + \frac{F_{\text{parallelizable}}}{\text{parallel}}}$

여기서 $\text{parallel} = 100$이고, $\text{Speed up}= 90$이다. 이를 만족하려면 병렬화 가능한 부분은 99.9 퍼센트 가량이 되어야 한다.

## Scaling
속도의 개선은 두 관점에서 바라볼 수 있다.

- Strong scaling: 작업/문제의 크기를 고정했을 때 멀티 프로세서에서 얻을 수 있는 속도 개선
- Weak scaling: 작업/문제의 크기가 프로세서 수에 비례할 때, 멀티 프로세서에서 얻을 수 있는 속도 개선

행렬 덧셈을 예시로 생각해보자. $m * n$의 두 행렬을 더하려면 $mn$의 문제 크기를 가진다고 볼 수 있다. Strong scaling은 행렬 크기를 고정해놓고, 멀티 프로세서에 의한 성능 향상을 확인하는 상황이고, weak scaling은 프로세서가 많아질 수록 행렬 크기도 늘려서 성능 향상을 확인하는 상황이다.

주어진 상황을 어떤 스케일링의 관점에서 보느냐는 상황에 따라 달려있다. 책의 예시를 빌리자면, 은행이 한 개 뿐이던 ATM을 100개로 늘린다고 해서, 한 고객이 100배나 그에 준하는 수준의 작업을 한다(strong scaling)고 보는 건 적절하지 않아 보인다. 대신, 100배나 그에 준하는 수준의 고객 수를 수용하고 처리할 수 있다(weak scaling)고 볼 수 있다. 이렇게 때때로 문제의 크기 또한 늘리는 게 타당한 경우가 있다.

일반적으로 weak scaling에 따른 문제를 해결하는 게 더 쉽다는 게 통념이지만, 문제가 너무 커져서 메모리 계층 구조에서 추가적인 비용이 발생한다면 이야기가 달라질 수도 있다. 

## Balancing
작업은 균일하게 분배될 때 가장 좋은 성능 개선이 이루어진다. 한 쪽에 치우치게 작업이 분배된다면, 그 프로세서는 하드웨어적인 소모도 더 겪을 뿐만 아니라, 많은 작업으로 인해 다른 프로세서를 기다리게 한다. 

### Example
> 어떤 작업은 병렬화 가능한 부분이 400, 그렇지 않은 부분이 10이다. 40개의 프로세서에 대해 부하의 균형이 이루어졌을 때, $10 + \frac{400}{40} = 20$으로, $20.5$배의 속도 향상이 이루어진다. 이 때, 단 하나의 프로세서에 대한 부하가 2배(5%) 증가한다면 어떻게 될까?

한 프로세서는 $400 * 0.05 = 20$만큼의 작업을 수행하고, 나머지 380의 작업은 39개의 프로세서가 분할한다. 이 때, 전체 수행 시간은 가장 마지막에 끝나는 프로세서의 시간을 따른다. 즉,

$T = max(\frac{380}{39}, \frac{20}{1}) + 10 = 30$

속도 개선의 수준은 $14$배로 줄었고, 나머지 39개의 프로세서는 약 9.7의 시간 동안만 일하고, 나머지 시간은 놀게 된다. 이용률이 떨어지는 셈이다.


# Parallel Hardwares
데이터 스트림과 명령어 스트림의 양상에 따라 하드웨어를 분류할 수 있다. 일반적인 단일 프로세서는 하나의 명령어 스트림과 하나의 데이터 스트림을 가지고, 일반적인 멀티 프로세서는 여러 명령어 스트림과 여러 데이터 스트림을 가진다.

![](/imgs/ca/ca15.png)

약어가 꽤 직관적이다.

## SIMD
SIMD 컴퓨터에선, 모든 프로세서가 같은 시점에 동일한 명령어를 수행한다. 말 그대로 단일 명령어 스트림인 셈이다. 그렇기에 다른 프로그램과 명령어를 저장할 추가적인 공간이 필요 없고, 제어를 위한 하드웨어에 대한 비용도 적은 편이다.

SIMD는 데이터 수준의 병렬성(data-level parallelism)이 보장된 프로그램에서 좋은 성능을 보인다. 즉, 동일 구조의 데이터가 많이 있는 벡터, 행렬 등의 연산에서 유리하다. (어레이 프로세서의 경우) 두 100차원 벡터를 더할 때, 우리는 100개의 데이터 스트림을 100개의 ALU를 통해 한 클럭 사이클 동안 계산할 수 있다. 

### Vector Processor
벡터 아키텍처는 SIMD의 조금 더 우아한 버전이다. ALU의 파이프라이닝과 다수의 원소를 저장할 수 있는 벡터 레지스터 집합이 핵심 아이디어다.

DAXPY(Double precision a x X plus Y)라 불리는 루프를 통해 확인해보자. DAXPY에선 2배 정밀도의 부동소수점인 스칼라 $a$와 64-벡터 $X, Y$를 사용한다. 아래는 일반적인 MIPS 코드다.

![](/imgs/ca/ca16.png)

아래는 벡터 명령어가 탑재된 MIPS 코드다. 접두어 $v$가 붙는 명령어는 동일 기능을 수행하는 벡터 연산이다.

![](/imgs/ca/ca17.png)

루프를 생각하면, 명령어의 개수는 거의 100분의 1로 줄어든 셈이다. 그에 따라 하드웨어의 부담도 덜하고, 파이프라이닝에서의 해저드 비율과 수행 시간도 크게 줄어든다. 

## HW Multithreading
하드웨어 멀티스레딩은 여러 스레드가 단일 프로세서를 겹쳐 사용함으로써 하드웨어 자원의 효율성을 향상시킨다. 멀티스레딩에서 각 스레드는 PC와 레지스터의 카피를 따로 가지고 있음을 기억하자. 스레드 간의 전환이 발생할 때마다 이들은 백업 및 복원된다. 아무튼 HW 멀티스레딩은 크게 두 방식에 의해 이루어진다.

- Fine-grain multithreading: 매 명령어(혹은 사이클)마다 스레드를 전환해 다수의 스레드를 인터리빙(interleaving)하며, 만약 전환된 스레드가 지연된 상태라면 바로 건너가는, 일종의 라운드 로빈 방식이다.
- Coarse-grain multithreading: 캐시 미스 등의 큰 수준의 지연이 발생할 때만 스레드의 전환을 수행한다.

두 방식은 각자의 장단점이 있다. 전자의 경우 지연되는 스레드의 비용을 감출 수 있다는 장점이 있지만, (바로 처리될 수도 있는) 개별 스레드의 수행이 느려지며, 스레드 전환 비용이 매우 작아야 한다는 단점이 있다. 후자의 경우 전자의 문제점들을 해결해주지만, 발생하는 작은 지연에 의한 비용을 감추지 못한다는 단점이 있다.

## SMT
SMT(Simulataneous MultiThreading)은 HW 멀티스레딩의 변형으로 볼 수 있다. 멀티 이슈(다수의 명령어를 한 번에 뽑아냄)가 가능하고 동적 스케줄링이 가능한 프로세서를 충분히 활용하여 멀티스레딩의 비용을 줄이는 방법이다.

기능 유닛이 사용 가능하다면 의존성이 없는 명령어를 최대한 이슈할 수 있고, 의존적인 명령어 또한 레지스터 재명명(renaming)과 동적 스케줄링으로 어느 정도 해결할 수 있다.

이러한 방식은 명령어를 최대한으로 이슈하고, 하드웨어를 최대한 활용할 수 있도록 한다.

![](/imgs/ca/ca18.png)

## SMP
SMP(Shared Memory multiProcessor)는 단일 주소공간을 갖는 멀티 프로세서를 의미한다. 우리가 접해온 대부분의 프로세서가 이 방식을 채택했을 것이다. 여기서 중요한 사항은 동기화(synchronization)다. 공유된 메모리는 일관적(consistent)이어야 한다. 어떤 변경되지 않은 공유 메모리에 대해, 어떤 프로세서는 A라고 읽고, 다른 프로세서는 B라고 읽으면 안될 것이다. 이를 위한 (lock과 같은) 여러 동기화 기법을 OS에서 배웠었다.

아무튼 SMP는 메모리 접근 시간에 따라 크게 두 스타일로 나뉜다.

- UMA: 어느 프로세서가 어느 워드에 접근하든 동일한 시간이 소요된다.
- NUMA: 워드나 프로세서에 따라 접근 시간이 다르다.

![](/imgs/ca/ca19.png)


# GPU
GPU는 용어 그대로 그래픽 처리를 위한 유닛이다. 그러한 목적에 특화되어 쉐이딩(shading), 텍스쳐 매핑(texture mapping) 등 다양한 그래픽 연산을 고수준의 성능으로 처리할 수 있다. CPU와 어느 정도 비슷한 구조와 기능을 가지지만, 몇 가지 중요한 차이점이 있다.

- CPU가 할 수 있는 모든 작업을 할 줄 알아야 하는 건 아니다. CPU와 GPU가 같이 탑재되면, GPU가 못하는 작업을 CPU가 하면 될 뿐이다. 
- GPU는 다단계 캐시를 사용하지 않고, HW 멀티스레딩을 이용해 지연을 감춘다.
- GPU는 지연보다는 처리율을 높이는 방향으로 설계된다. 
- 큰 대역폭을 얻기 위해 고도로 멀티스레딩되어 있고, 더 많은 프로세서를 지닌다.

GPU는 그래픽 처리를 목적으로 만들어졌지만, 이러한 특성을 잘 활용하여 그래픽 처리 외의 특정 목적에 사용할 수 있다. 비트코인을 그래픽 카드로 채굴하는 걸 생각하면 알기 쉽다. (벡터 아키텍처처럼) 대개 데이터 수준의 병렬성을 포함하는 문제를 해결하는 데 용이하다.

요즘은 기본적인 기능과 목적(그래픽 처리)에서의 좋은 성능을 유지하면서, 그것의 기능을 조금 더 확장해나가는 방향으로 연구 개발이 이루어지고 있다. 

딱히 중요해보이진 않아서 디테일을 다루진 않았다.


# 마치며
우리는 멀티 프로세서를 통해 높은 성능을 이끌어내기 위한 방법들을 알아보았다. 이는 응용 소프트웨어 레벨과 아키텍처 레벨 모두에서의 긴밀한 협력이 필요해서 많은 어려움을 낳지만, 이러한 문제를 해결하기 위한 많은 인터페이스와 구조적 개선이 이루어지고 있다. 

교과서 정리는 여기서 끝인데, 앞으로 생각나는 게 있으면 더 정리할 예정이다.